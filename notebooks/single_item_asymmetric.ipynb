{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Player FPSB Auction with assymetric uniform valuation distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "root_path = os.path.join(os.path.expanduser('~'), 'bnelearn')\n",
    "if root_path not in sys.path:\n",
    "    sys.path.append(root_path)\n",
    "import time\n",
    "from timeit import default_timer as timer\n",
    "from functools import partial\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils as ut\n",
    "from torch.optim.optimizer import Optimizer, required\n",
    "\n",
    "from bnelearn.strategy import NeuralNetStrategy, ClosureStrategy\n",
    "from bnelearn.bidder import Bidder\n",
    "from bnelearn.mechanism import FirstPriceSealedBidAuction, VickreyAuction\n",
    "from bnelearn.learner import ESPGLearner\n",
    "from bnelearn.environment import AuctionEnvironment\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set up matplotlib\n",
    "is_ipython = 'inline' in plt.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "plt.rcParams['figure.figsize'] = [10, 7]\n",
    "    \n",
    "cuda = torch.cuda.is_available()\n",
    "device = 'cuda' if cuda else 'cpu'\n",
    "\n",
    "# Use specific cuda gpu if desired (i.e. for running multiple experiments in parallel)\n",
    "specific_gpu = 3\n",
    "if cuda and specific_gpu:\n",
    "    torch.cuda.set_device(specific_gpu)\n",
    "\n",
    "print(device)\n",
    "if cuda: print(torch.cuda.current_device())\n",
    "    \n",
    "seed = 8\n",
    "if seed is not None:\n",
    "    torch.random.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log in notebook folder\n",
    "# alternative for shared access to experiments:\n",
    "#log_root = os.path.abspath('/srv/bnelearn/experiments')\n",
    "log_root = os.path.join(root_path, 'experiments')\n",
    "#log_root = os.path.abspath('.')\n",
    "run_comment = str(seed) + str('_pretrain')\n",
    "#save_figure_data_to_disc = False\n",
    "save_figure_to_disc_png = True\n",
    "save_figure_to_disc_svg = True\n",
    "show_plot_inline = False\n",
    "\n",
    "## Experiment setup\n",
    "n_players = 2\n",
    "n_items = 1\n",
    "# valuation distribution\n",
    "# both players should have same lower bound\n",
    "u_lo =   5.\n",
    "u0_hi = 15.\n",
    "u1_hi = 25.\n",
    "u_his = [u0_hi, u1_hi]\n",
    "\n",
    "pretrain_iters = 500\n",
    "\n",
    "def strat_to_bidder(strategy, batch_size, player_position):\n",
    "    return Bidder.uniform(u_lo, u_his[player_position], strategy, player_position=player_position, batch_size = batch_size)\n",
    "\n",
    "## Environment settings\n",
    "#training batch size\n",
    "batch_size = 2**17\n",
    "eval_batch_size = 2**25\n",
    "epoch = 5000\n",
    "\n",
    "# strategy model architecture\n",
    "input_length = 1\n",
    "hidden_nodes = [10, 10]\n",
    "hidden_activations = [nn.SELU(), nn.SELU()]\n",
    "\n",
    "\n",
    "learner_hyperparams = {\n",
    "    'population_size': 64,\n",
    "    'sigma': 1.,\n",
    "    'scale_sigma_by_model_size': True\n",
    "}\n",
    "\n",
    "### Optimizer hyperparams\n",
    "# SGD standards\n",
    "    #'lr': 1e-3,\n",
    "    #'momentum': 0.7\n",
    "# Adam standards:\n",
    "    # 'lr': 1e-3\n",
    "    # 'betas': (0.9, 0.999), #coefficients for running avgs of grad and square grad\n",
    "    # 'eps': 1e-8 , # added to denominator for numeric stability\n",
    "    # 'weight_decay': 0, #L2-decay\n",
    "    # 'amsgrad': False #whether to use amsgrad-variant\n",
    "optimizer_type = torch.optim.SGD\n",
    "optimizer_hyperparams ={    \n",
    "    'lr': 1e-3,\n",
    "    'momentum': 0.5\n",
    "}\n",
    "\n",
    "# plot and log training options\n",
    "plot_epoch = 50\n",
    "plot_points = min(150, batch_size)\n",
    "\n",
    "plot_xmin = u_lo\n",
    "plot_xmax = u1_hi\n",
    "plot_ymin = 0\n",
    "plot_ymax = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For $v_1 \\sim U(\\alpha, \\beta_1)$, $v_2 \\sim U(\\alpha, \\beta_2)$, and with\n",
    "\n",
    "$$c = \\frac{1}{(\\beta_1 - \\alpha)²} -\\frac{1}{(\\beta_2 - \\alpha)²}, $$\n",
    "\n",
    "the equilibrium bids are given by\n",
    "\n",
    "$$b_1^*(v_1) = \\alpha + \\frac{v_1 - \\alpha}{1 + \\sqrt{1-c(v_1-\\alpha)²}} $$\n",
    "\n",
    "$$b_2^*(v_2) = \\alpha + \\frac{v_2 - \\alpha}{1 + \\sqrt{1-c(v_2-\\alpha)²}} $$\n",
    "\n",
    "(See https://link.springer.com/article/10.1007/BF01271133\n",
    "\n",
    "The expected utility in the bne can then be calculated using\n",
    "\n",
    "$$E[u_{BNE}] = \\int_{0}^{\\infty}{P(win | b) * u(b,v | win) *f(v) dv} = ???$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for evaluation\n",
    "# helper constant\n",
    "c = 1 / (u0_hi - u_lo)**2 - 1 / (u1_hi - u_lo)**2\n",
    "def optimal_bid(valuation: torch.Tensor or np.ndarray or float,\n",
    "                player_position: int) -> torch.Tensor:\n",
    "    #print(c)\n",
    "    \n",
    "    if not isinstance(valuation, torch.Tensor):\n",
    "        valuation = torch.tensor(valuation, dtype=torch.float)\n",
    "    #unsqueeze if simple float\n",
    "    if valuation.dim() == 0:\n",
    "        valuation.unsqueeze_(0)\n",
    "    \n",
    "    if player_position == 0:\n",
    "        # weak player\n",
    "        return u_lo + (valuation - u_lo) / (1 + torch.sqrt(1 - c*(valuation - u_lo)**2))\n",
    "    elif player_position == 1:\n",
    "        # strong player\n",
    "        return u_lo + (valuation - u_lo) / (1 + torch.sqrt(1 + c*(valuation - u_lo)**2))\n",
    "\n",
    "def setup_custom_scalar_plots(writer):    \n",
    "    ## define layout first, then call add_custom_scalars once\n",
    "    layout = {\n",
    "        'eval': {\n",
    "            'Utilities (SP and BNE)':  ['Multiline',\n",
    "                                     ['eval_players/p{}_utility'.format(i)       for i in range(n_players)]],\n",
    "            'Utilities Self Play':  ['Multiline',\n",
    "                                     ['eval_players/p{}_utility_sp'.format(i)       for i in range(n_players)]],\n",
    "            'Utilities vs BNE':     ['Multiline',\n",
    "                                     ['eval_players/p{}_utility_vs_bne'.format(i)   for i in range(n_players)]],\n",
    "            'Loss vs BNE absolute': ['Multiline',\n",
    "                                     ['eval_players/p{}_epsilon_absolute'.format(i) for i in range(n_players)]],\n",
    "            'Loss vs BNE relative': ['Multiline',\n",
    "                                     ['eval_players/p{}_epsilon_relative'.format(i) for i in range(n_players)]]\n",
    "            #'How to make a margin chart': ['Margin', ['tag_mean', 'tag_min', 'tag_max']]\n",
    "        }\n",
    "    }    \n",
    "    writer.add_custom_scalars(layout) \n",
    "\n",
    "def log_once(writer, e):\n",
    "    \"\"\"Everything that should be logged only once on initialization.\"\"\"\n",
    "    for i in range(n_players):\n",
    "        writer.add_scalar('debug_players/p{}_model_parameters'.format(i), n_parameters[i], e)\n",
    "    writer.add_scalar('debug/model_parameters', sum(n_parameters), e)\n",
    "    writer.add_scalar('debug/eval_batch_size', eval_batch_size, e)\n",
    "    writer.add_text('hyperparams/neural_net_spec', str(model_1), 0)    \n",
    "    #writer.add_scalar('debug/eval_batch_size', eval_batch_size, e)\n",
    "    writer.add_graph(model_1, env.agents[0].valuations)    \n",
    "\n",
    "def log_hyperparams(writer, e):\n",
    "#     writer.add_scalar('hyperparams/batch_size', batch_size, e)\n",
    "#     writer.add_scalar('hyperparams/batch_size', batch_size, e)\n",
    "#     writer.add_scalar('hyperparams/learning_rate', learning_rate, e)\n",
    "#     writer.add_scalar('hyperparams/momentum', momentum, e)\n",
    "#     writer.add_scalar('hyperparams/sigma', sigma, e)\n",
    "#     writer.add_scalar('hyperparams/n_perturbations', n_perturbations, e)\n",
    "    pass\n",
    "        \n",
    "def log_metrics(writer, u, u_vs_bne, e):\n",
    "    \"\"\"log scalar for each player. Tensor should be of shape n_players\"\"\"\n",
    "    epsilons_rel = eps_rel(u_vs_bne)\n",
    "    epsilons_abs = eps_abs(u_vs_bne)\n",
    "    \n",
    "    # redundant logging of utlities for multiline\n",
    "    for i in range(n_players):\n",
    "        ## Note: multiline chart capture all tags that match the given beginning of the tag_name,\n",
    "        ## i.e. eval/utility will match all of  eval/utility, eval/utility_sp and eval/utlity_vs_bne\n",
    "        ## thus self play utility should be named utility_sp to be able to capture it by itself later.\n",
    "        writer.add_scalar('eval_players/p{}_utility_sp'.format(i), u[i], e)\n",
    "        writer.add_scalar('eval_players/p{}_utility_vs_bne'.format(i), u_vs_bne[i], e)\n",
    "        writer.add_scalar('eval_players/p{}_epsilon_absolute'.format(i), epsilons_abs[i], e)\n",
    "        writer.add_scalar('eval_players/p{}_epsilon_relative'.format(i), epsilons_rel[i], e)\n",
    "    \n",
    "    writer.add_scalar('eval/epsilon_relative', epsilons_rel.mean(),e)\n",
    "    writer.add_scalar('debug/epsilon_absolute', epsilons_abs.mean(),e)\n",
    "\n",
    "v0_opt = np.linspace(u_lo, u0_hi, 25)\n",
    "b0_opt = optimal_bid(v0_opt, 0).numpy()\n",
    "v1_opt = np.linspace(u_lo, u1_hi, 50)\n",
    "b1_opt = optimal_bid(v1_opt, 1).numpy()\n",
    "    \n",
    "def plot_bid_function(fig, v0,b0, v1, b1, writer=None, e=None):\n",
    "    #plot_points = min(plot_points, len(v1), len(v2))\n",
    "    \n",
    "    # subsample points and plot    \n",
    "    v0 = v0.detach().cpu().numpy()[:plot_points]\n",
    "    b0 = b0.detach().cpu().numpy()[:plot_points]\n",
    "    v1 = v1.detach().cpu().numpy()[:plot_points]\n",
    "    b1 = b1.detach().cpu().numpy()[:plot_points]\n",
    "    \n",
    "#     if save_vectors_to_disc:\n",
    "#         np.savez(\n",
    "#             os.path.join(logdir, 'figure_data.npz'),\n",
    "#             v0_opt = v0_opt,\n",
    "#             b0_opt = b0_opt,\n",
    "#             v1_opt = v1_opt,\n",
    "#             b1_opt = b1_opt,\n",
    "#             v0 = v0, b0 = b0, v1=v1, b1=b1\n",
    "#         )\n",
    "        \n",
    "    fig = plt.gcf()\n",
    "    plt.cla()\n",
    "    plt.xlim(plot_xmin, plot_xmax)\n",
    "    plt.ylim(plot_ymin, plot_ymax)\n",
    "    plt.xlabel('valuation')\n",
    "    plt.ylabel('bid')\n",
    "    plt.text(plot_xmin + 0.05*(plot_xmax - plot_xmin),\n",
    "             plot_ymax - 0.05*(plot_ymax - plot_ymin),\n",
    "             'iteration {}'.format(e))\n",
    "    plt.plot(v0,b0, 'bo', v0_opt, b0_opt, 'b--', v1,b1, 'ro', v1_opt,b1_opt, 'r--')\n",
    "    \n",
    "    if save_figure_to_disc_png:\n",
    "        plt.savefig(os.path.join(logdir, 'png', f'epoch_{e:05}.png'))\n",
    "\n",
    "    if save_figure_to_disc_svg:\n",
    "            plt.savefig(os.path.join(logdir, 'svg', f'epoch_{e:05}.svg'),\n",
    "                        format='svg', dpi=1200)\n",
    "\n",
    "    if show_plot_inline:\n",
    "            #display.display(plt.gcf())\n",
    "            plt.show()\n",
    "    if writer:\n",
    "        writer.add_figure('eval/bid_function', fig, e)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the model.\n",
    "We'll ensure the initialization provides positive outputs on the domain we are interested in, as otherwise we can't learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize models\n",
    "model_0 = NeuralNetStrategy(input_length,                            \n",
    "                            hidden_nodes = hidden_nodes,\n",
    "                            hidden_activations = hidden_activations,\n",
    "                            ensure_positive_output = torch.tensor([float(u0_hi)])\n",
    "                            ).to(device)\n",
    "   \n",
    "\n",
    "model_1 = NeuralNetStrategy(input_length,\n",
    "                            hidden_nodes = hidden_nodes,\n",
    "                            hidden_activations = hidden_activations,\n",
    "                            ensure_positive_output = torch.tensor([float(u1_hi)])\n",
    "                            ).to(device)\n",
    "\n",
    "n_parameters = [sum([p.numel() for p in model_0.parameters()]),sum([p.numel() for p in model_0.parameters()])]\n",
    "\n",
    "bidder_0 = strat_to_bidder(model_0, batch_size, player_position=0)\n",
    "bidder_1 = strat_to_bidder(model_1, batch_size, player_position=1)\n",
    "\n",
    "\n",
    "mechanism = FirstPriceSealedBidAuction(cuda = True)\n",
    "env = AuctionEnvironment(mechanism,\n",
    "                  agents = [bidder_0, bidder_1],\n",
    "                  batch_size = batch_size,\n",
    "                  n_players =n_players,\n",
    "                  strategy_to_player_closure = strat_to_bidder\n",
    "                 )\n",
    "learner_0 = ESPGLearner(\n",
    "    model = model_0,\n",
    "    environment = env,\n",
    "    hyperparams = learner_hyperparams,\n",
    "    optimizer_type = optimizer_type,\n",
    "    optimizer_hyperparams = optimizer_hyperparams,\n",
    "    strat_to_player_kwargs={\"player_position\":0})\n",
    "\n",
    "learner_1 = ESPGLearner(\n",
    "    model = model_1,\n",
    "    environment = env,\n",
    "    hyperparams = learner_hyperparams,\n",
    "    optimizer_type = optimizer_type,\n",
    "    optimizer_hyperparams = optimizer_hyperparams,    \n",
    "    strat_to_player_kwargs={\"player_position\":1})\n",
    "\n",
    "\n",
    "\n",
    "print(model_0)\n",
    "print('Total parameters: ' + str(n_parameters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up equilibrium-environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bne_strategies = [\n",
    "    ClosureStrategy(partial(optimal_bid, player_position=i))\n",
    "    for i in range(n_players)\n",
    "]\n",
    "\n",
    "bne_env = AuctionEnvironment(\n",
    "    mechanism,\n",
    "    agents = [strat_to_bidder(bne_strategies[i], player_position=i, batch_size=eval_batch_size)\n",
    "              for i in range(n_players)],\n",
    "    n_players = n_players,\n",
    "    batch_size = eval_batch_size,\n",
    "    strategy_to_player_closure = strat_to_bidder\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pretrain_iters > 0:\n",
    "    model_0.pretrain(bidder_0.valuations, pretrain_iters)\n",
    "    model_1.pretrain(bidder_1.valuations, pretrain_iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#print(\"Utility in BNE (analytical): \\t{:.5f}\".format(bne_utility))\n",
    "bne_utilities_sampled = torch.tensor([bne_env.get_reward(a, draw_valuations = True) for a in bne_env.agents])\n",
    "print(('Utilities in BNE (sampled):'+ '\\t{:.5f}'*n_players + '.').format(*bne_utilities_sampled))\n",
    "\n",
    "if u0_hi==15 and u1_hi ==25 and u_lo==5:\n",
    "    # replace by known optimum with higher precision\n",
    "    bne_utilities_sampled = torch.tensor([0.9694, 5.0688]) # calculated using 100x batch size above\n",
    "\n",
    "eps_abs = lambda us: bne_utilities_sampled - us\n",
    "eps_rel = lambda us: 1- us/bne_utilities_sampled\n",
    "\n",
    "utilities_vs_bne = torch.tensor([bne_env.get_strategy_reward(a.strategy, player_position=i) for i,a in enumerate(env.agents)])\n",
    "print(('Model utility vs BNE: \\t'+'\\t{:.5f}'*n_players).format(*utilities_vs_bne))\n",
    "\n",
    "utilities_learning_env = torch.tensor([env.get_strategy_reward(a.strategy, player_position=i, draw_valuations = True) for i,a in enumerate(env.agents)])\n",
    "print(('Model utility in learning env:'+'\\t{:.5f}'*n_players).format(*utilities_learning_env))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bidder_0.draw_valuations_()\n",
    "v_0 = bidder_0.valuations\n",
    "b_0 = bidder_0.get_action()\n",
    "bidder_1.draw_valuations_()\n",
    "v_1 = bidder_1.valuations\n",
    "b_1 = bidder_1.get_action()\n",
    "fig = plt.figure()\n",
    "plot_bid_function(fig, v_0, b_0, v_1, b_1, writer=None,e=0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(log_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.name == 'nt': raise ValueError('The run_name may not contain : on Windows! (change datetime format to fix this)') \n",
    "run_name = time.strftime('%Y-%m-%d %a %H:%M:%S')\n",
    "if run_comment:\n",
    "    run_name = run_name + ' - ' + str(run_comment)\n",
    "logdir = os.path.join(log_root, 'single_item', 'first_price',  'uniform', 'asymmetric', str(n_players) + 'p', run_name)\n",
    "print(logdir)\n",
    "os.makedirs(logdir, exist_ok=False)\n",
    "if save_figure_to_disc_png:\n",
    "    os.mkdir(os.path.join(logdir, 'png'))\n",
    "if save_figure_to_disc_svg:\n",
    "    os.mkdir(os.path.join(logdir, 'svg'))\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [10, 7]\n",
    "with SummaryWriter(logdir, flush_secs=60) as writer:\n",
    "    \n",
    "  \n",
    "    setup_custom_scalar_plots(writer)\n",
    "    \n",
    "    \n",
    "    overhead_mins = 0\n",
    "    torch.cuda.empty_cache()\n",
    "    log_once(writer, 0)\n",
    "    log_hyperparams(writer, 0)\n",
    "    fig = plt.figure()\n",
    "    \n",
    "    \n",
    "    # plot current function output\n",
    "    bidder_0.draw_valuations_()\n",
    "    v_0 = bidder_0.valuations\n",
    "    b_0 = bidder_0.get_action()\n",
    "    bidder_1.draw_valuations_()\n",
    "    v_1 = bidder_1.valuations\n",
    "    b_1 = bidder_1.get_action()\n",
    "    plot_bid_function(fig, v_0, b_0, v_1, b_1, writer,e=0) \n",
    "    \n",
    "    for e in range(epoch+1):\n",
    "\n",
    "        # always: do optimizer step\n",
    "        utility_0 = learner_0.update_strategy_and_evaluate_utility()\n",
    "        utility_1 = learner_1.update_strategy_and_evaluate_utility()\n",
    "        \n",
    "        #logging \n",
    "        start_time = timer()\n",
    "        utilities = torch.tensor([utility_0, utility_1])\n",
    "        utilities_vs_bne = torch.tensor([bne_env.get_strategy_reward(a.strategy, player_position=i) for i,a in enumerate(env.agents)])\n",
    "        log_metrics(writer, utilities, utilities_vs_bne, e)\n",
    "\n",
    "        if e % plot_epoch == 0:\n",
    "            \n",
    "            # plot current function output\n",
    "            bidder_0.draw_valuations_()\n",
    "            v_0 = bidder_0.valuations\n",
    "            b_0 = bidder_0.get_action()\n",
    "            bidder_1.draw_valuations_()\n",
    "            v_1 = bidder_1.valuations\n",
    "            b_1 = bidder_1.get_action()    \n",
    "            \n",
    "            print(\"Epoch {}: \\tutilities: \\t p0: {:.3f} \\t p1: {:.3f}\".format(e, utility_0, utility_1))\n",
    "            plot_bid_function(fig, v_0, b_0, v_1, b_1, writer,e)            \n",
    "        \n",
    "        elapsed = timer() - start_time\n",
    "        overhead_mins = overhead_mins + elapsed/60\n",
    "        writer.add_scalar('debug/overhead_mins', overhead_mins, e)\n",
    "            \n",
    "                     \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
