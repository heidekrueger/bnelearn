{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook is deprecated\n",
    "\n",
    "## Its functionality has been implemented in run_single_item_auction.py\n",
    "## Some implementations are even missing here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, time, warnings\n",
    "root_path = os.path.abspath(os.path.join('..'))\n",
    "if root_path not in sys.path:\n",
    "    sys.path.append(root_path)\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "import numpy as np\n",
    "import scipy.integrate as integrate\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils as ut\n",
    "from torch.optim.optimizer import Optimizer, required\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from bnelearn.strategy import NeuralNetStrategy, ClosureStrategy\n",
    "from bnelearn.bidder import Bidder\n",
    "from bnelearn.mechanism import FirstPriceSealedBidAuction, VickreyAuction\n",
    "from bnelearn.learner import ESPGLearner\n",
    "from bnelearn.environment import AuctionEnvironment\n",
    "from bnelearn.experiment import Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Settings\n",
    "# device and seed\n",
    "cuda = True\n",
    "specific_gpu = 3\n",
    "seed = None\n",
    "\n",
    "# run settings\n",
    "epochs = 1000\n",
    "run_comment = '' # used in log title in addition to datetime\n",
    "\n",
    "# Logging and plotting\n",
    "logging_options = dict(\n",
    "    log_root = os.path.abspath('.'),    \n",
    "    save_figure_to_disk_png = False,\n",
    "    save_figure_to_disk_svg = False, #for publishing. better quality but a pain to work with\n",
    "    plot_epoch = 100,\n",
    "    show_plot_inline = True\n",
    ")\n",
    "\n",
    "# Experiment setting parameters\n",
    "n_players = 2\n",
    "auction_mechanism = 'first_price' # one of 'first_price', 'second_price'\n",
    "valuation_prior = 'uniform' # for now, one of 'uniform' / 'normal', specific params defined in script\n",
    "risk_alpha = 1.0 # optimal strategy for alpha!= 1.0 only known for uniform first price\n",
    "\n",
    "# Learning\n",
    "model_sharing = True\n",
    "pretrain_iters = 10\n",
    "batch_size = 2**18\n",
    "## ES\n",
    "learner_hyperparams = {\n",
    "    'population_size': 64,\n",
    "    'sigma': 1.,\n",
    "    'scale_sigma_by_model_size': True\n",
    "}\n",
    "## Optimizer\n",
    "            # SGD standards\n",
    "            #'lr': 1e-3,\n",
    "            #'momentum': 0.7\n",
    "            # Adam standards:\n",
    "            # 'lr': 1e-3\n",
    "            # 'betas': (0.9, 0.999), #coefficients for running avgs of grad and square grad\n",
    "            # 'eps': 1e-8 , # added to denominator for numeric stability\n",
    "            # 'weight_decay': 0, #L2-decay\n",
    "            # 'amsgrad': False #whether to use amsgrad-variant\n",
    "optimizer_type = torch.optim.Adam\n",
    "optimizer_hyperparams ={    \n",
    "    'lr': 3e-3\n",
    "}\n",
    "\n",
    "# Evaluation\n",
    "eval_batch_size = 2**24\n",
    "cache_eval_actions = True\n",
    "n_processes_optimal_strategy = 44 if valuation_prior != 'uniform' and auction_mechanism != 'second_price' else 0\n",
    "\n",
    "# in single item auctions there's only a single input\n",
    "### strategy model architecture\n",
    "input_length = 1\n",
    "hidden_nodes = [5, 5]\n",
    "hidden_activations = [nn.SELU(), nn.SELU()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up matplotlib\n",
    "is_ipython = 'inline' in plt.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "plt.rcParams['figure.figsize'] = [8, 5]\n",
    "\n",
    "### set device settings\n",
    "if cuda and not torch.cuda.is_available():\n",
    "    warnings.warn('Cuda not available. Falling back to CPU!')\n",
    "    cuda = False\n",
    "device = 'cuda' if cuda else 'cpu'\n",
    "\n",
    "if cuda and specific_gpu:\n",
    "    torch.cuda.set_device(specific_gpu)\n",
    "    \n",
    "### Set up random seeds\n",
    "if seed is not None:\n",
    "    torch.random.manual_seed(manual_seed)\n",
    "    torch.cuda.manual_seed_all(manual_seed)\n",
    "\n",
    "### Game setup\n",
    "if auction_mechanism == 'first_price' :\n",
    "    mechanism = FirstPriceSealedBidAuction(cuda = cuda)\n",
    "elif auction_mechanism == 'second_price':\n",
    "    mechanism = VickreyAuction(cuda = cuda)\n",
    "    \n",
    "### Set up experiment domain and bidders\n",
    "if valuation_prior == 'uniform':\n",
    "    u_lo =0\n",
    "    u_hi =10\n",
    "    common_prior = torch.distributions.uniform.Uniform(low = u_lo, high = u_hi)\n",
    "\n",
    "    positive_output_point = u_hi\n",
    "    def strat_to_bidder(strategy, batch_size=batch_size, player_position=None, cache_actions=False):\n",
    "        return Bidder.uniform(u_lo, u_hi, strategy, batch_size = batch_size,\n",
    "                              player_position=player_position, cache_actions=cache_actions, risk_alpha = risk_alpha)\n",
    "    plot_xmin = u_lo\n",
    "    plot_xmax = u_hi\n",
    "    plot_ymin = 0\n",
    "    plot_ymax = 10\n",
    "\n",
    "elif valuation_prior == 'normal':\n",
    "    if risk_alpha != 1.0:\n",
    "        warnings.warn('No analytical setting with risk_alpha != 1 for normal priors. Did you mean to set risk_alpha=1?')\n",
    "    valuation_mean = 10.0\n",
    "    valuation_std = 5.0\n",
    "    common_prior = torch.distributions.normal.Normal(loc = valuation_mean, scale = valuation_std)\n",
    "    positive_output_point = valuation_mean\n",
    "\n",
    "    plot_xmin = int(max(0, valuation_mean - 3*valuation_std))\n",
    "    plot_xmax = int(valuation_mean + 3*valuation_std)\n",
    "    plot_ymin = 0\n",
    "    plot_ymax = 20 if auction_mechanism == 'first_price' else plot_xmax\n",
    "    def strat_to_bidder(strategy, batch_size=batch_size, player_position=None, cache_actions=False):\n",
    "        return Bidder.normal(valuation_mean, valuation_std, strategy,\n",
    "                             batch_size = batch_size,\n",
    "                             player_position=player_position,\n",
    "                             cache_actions=cache_actions)\n",
    "else:\n",
    "    raise ValueError('Only normal and uniform priors supported by this script.')\n",
    "\n",
    "def setup_bidders(self, model_sharing = True):\n",
    "    if model_sharing:  \n",
    "        print('Model Sharing...')\n",
    "        self.model = NeuralNetStrategy(\n",
    "            input_length, hidden_nodes = hidden_nodes,hidden_activations = hidden_activations,\n",
    "            ensure_positive_output = torch.tensor([float(u_hi)])\n",
    "            ).to(device)\n",
    "\n",
    "\n",
    "        self.bidders = [strat_to_bidder(self.model, batch_size, player_position)\n",
    "                   for player_position in range(n_players)]\n",
    "        if pretrain_iters > 0:\n",
    "            print('pretraining')\n",
    "            self.model.pretrain(self.bidders[0].valuations, pretrain_iters)\n",
    "    else:\n",
    "        raise NotImplementedError(\"only model sharing has been implemented.\")\n",
    "        \n",
    "### Setup Learning Environment and Learner(s)\n",
    "def setup_learning_environment(self): self.env = AuctionEnvironment(self.mechanism, agents = self.bidders,\n",
    "                                  batch_size = batch_size, n_players =n_players,\n",
    "                                  strategy_to_player_closure = strat_to_bidder)\n",
    "def setup_learner(self):   self.learner = ESPGLearner(\n",
    "        model = self.model, environment = self.env, hyperparams = learner_hyperparams,\n",
    "        optimizer_type = optimizer_type, optimizer_hyperparams = optimizer_hyperparams)\n",
    "    \n",
    "    \n",
    "### Setup Evaluation\n",
    "# for evaluation\n",
    "if auction_mechanism == 'second_price':\n",
    "    def optimal_bid(valuation): return valuation\n",
    "elif auction_mechanism == 'first_price':\n",
    "    if valuation_prior == 'uniform':\n",
    "        def optimal_bid(valuation):\n",
    "            return valuation * (n_players - 1) / (n_players - 1 + risk_alpha)\n",
    "    elif valuation_prior == 'normal':\n",
    "        import scipy.integrate as integrate\n",
    "        common_prior = torch.distributions.normal.Normal(loc = valuation_mean, scale = valuation_std)\n",
    "\n",
    "        def optimal_bid(valuation: torch.Tensor or np.ndarray or float) -> torch.Tensor:    \n",
    "            # For float and numpy --> convert to tensor\n",
    "            if not isinstance(valuation, torch.Tensor):\n",
    "                valuation = torch.tensor(valuation, dtype = torch.float)           \n",
    "            # For float / 0d tensors --> unsqueeze to allow list comprehension below\n",
    "            if valuation.dim() == 0:\n",
    "                valuation.unsqueeze_(0)\n",
    "\n",
    "            # shorthand notation for F^(n-1)\n",
    "            Fpowered = lambda v: torch.pow(common_prior.cdf(v), n_players - 1)  \n",
    "\n",
    "            # do the calculations\n",
    "            numerator = torch.tensor(\n",
    "                    [integrate.quad(Fpowered, 0, v)[0] for v in valuation],\n",
    "                    device = valuation.device\n",
    "                ).reshape(valuation.shape)                                 \n",
    "            return valuation - numerator / Fpowered(valuation)\n",
    "else:\n",
    "    raise ValueError(\"unknown auction mechanism.\")\n",
    "\n",
    "bneStrategy = ClosureStrategy(optimal_bid, parallel=n_processes_optimal_strategy)\n",
    "\n",
    "if auction_mechanism == 'first_price':\n",
    "    if valuation_prior == 'uniform':\n",
    "        global_bne_utility = risk_alpha/(n_players - 1 + risk_alpha)*(u_hi - u_lo)/(n_players+1)\n",
    "    elif valuation_prior == 'normal':\n",
    "        if risk_alpha != 1.0:\n",
    "            warnings.warn('Risk aversion ignored in optimal bid for Gaussian priors!')\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter('ignore')\n",
    "            # don't print scipy accuracy warnings\n",
    "            global_bne_utility, analytical_error = integrate.dblquad(\n",
    "                lambda x, v: common_prior.cdf(x)**(n_players - 1) * common_prior.log_prob(v).exp(),\n",
    "                0, float('inf'), # outer boundaries\n",
    "                lambda v: 0, lambda v: v) # inner boundaries\n",
    "            global_bne_utility_sampled = global_bne_env.get_reward(global_bne_env.agents[0], draw_valuations=True)\n",
    "            if analytical_error > 1e-7:\n",
    "                warnings.warn('Error in optimal utility might not be negligible')\n",
    "        print(\"Utility in BNE (analytical): \\t{:.5f}\".format(global_bne_utility))\n",
    "        print('Utility in BNE (sampled): \\t{:.5f}'.format(global_bne_utility_sampled))\n",
    "elif auction_mechanism == 'second_price':\n",
    "    F = lambda x: common_prior.cdf(x)\n",
    "    f = lambda x: common_prior.log_prob(torch.tensor(x)).exp()\n",
    "    f1n = lambda x,n: n * F(x)**(n - 1) * f(x)\n",
    "\n",
    "    global_bne_utility, error_estimate = integrate.dblquad(\n",
    "        lambda x,v: (v-x) * f1n(x, n_players-1) * f(v) ,\n",
    "        0, float('inf'), # outer boundaries\n",
    "        lambda v: 0, lambda v: v) # inner boundaries\n",
    "\n",
    "    if error_estimate > 1e-6:\n",
    "        warnings.warn('Error bound on analytical bne utility is not negligible!')\n",
    "else:\n",
    "    raise ValueError(\"Invalid auction mechanism.\")\n",
    "\n",
    "def setup_eval_environment(self):\n",
    "        # environment filled with optimal players for logging\n",
    "        # use higher batch size for calculating optimum\n",
    "        self.bne_env = global_bne_env\n",
    "        self.bne_utility = global_bne_utility\n",
    "\n",
    "    \n",
    "### Setup Plotting\n",
    "plot_points = min(100, batch_size)\n",
    "v_opt = np.linspace(plot_xmin, plot_xmax, 100)\n",
    "b_opt = optimal_bid(v_opt)\n",
    "def plot_bid_function(self, fig, plot_data, writer=None, e=None):\n",
    "    v,b = plot_data    \n",
    "    v = v.detach().cpu().numpy()[:plot_points]\n",
    "    b= b.detach().cpu().numpy()[:plot_points]\n",
    "    \n",
    "    # create the plot\n",
    "    fig = plt.gcf()\n",
    "    plt.cla()\n",
    "    plt.xlim(plot_xmin, plot_xmax)\n",
    "    plt.ylim(plot_ymin, plot_ymax)\n",
    "    plt.xlabel('valuation')\n",
    "    plt.ylabel('bid')\n",
    "    plt.text(plot_xmin + 0.05*(plot_xmax - plot_xmin),\n",
    "             plot_ymax - 0.05*(plot_ymax - plot_ymin),\n",
    "             'iteration {}'.format(e))\n",
    "    plt.plot(v,b, 'o', v_opt, b_opt, 'r--')    \n",
    "    #show and/or log    \n",
    "    self._process_figure(fig, writer, e)\n",
    "        \n",
    "## Setup logging\n",
    "def log_once(self, writer, e):\n",
    "    \"\"\"Everything that should be logged only once on initialization.\"\"\"\n",
    "    #writer.add_scalar('debug/total_model_parameters', n_parameters, e)\n",
    "    #writer.add_text('hyperparams/neural_net_spec', str(self.model), 0)    \n",
    "    #writer.add_scalar('debug/eval_batch_size', eval_batch_size, e)\n",
    "    writer.add_graph(self.model, self.env.agents[0].valuations)    \n",
    "    \n",
    "def log_metrics(self, writer, e):\n",
    "    writer.add_scalar('eval/utility', self.utility, e)\n",
    "    writer.add_scalar('debug/norm_parameter_update', self.update_norm, e)\n",
    "    writer.add_scalar('eval/utility_vs_bne', self.utility_vs_bne, e)\n",
    "    writer.add_scalar('eval/epsilon_relative', self.epsilon_relative, e)\n",
    "    writer.add_scalar('eval/epsilon_absolute', self.epsilon_absolute, e) # debug because only interesting to see if numeric precision is a problem, otherwise same as relative but scaled.\n",
    "\n",
    "# TODO: deferred until writing logger\n",
    "def log_hyperparams(self, writer, e):\n",
    "    \"\"\"Everything that should be logged on every learning_rate updates\"\"\"\n",
    "#     writer.add_scalar('hyperparams/batch_size', batch_size, e)\n",
    "#     writer.add_scalar('hyperparams/learning_rate', learning_rate, e)\n",
    "#     writer.add_scalar('hyperparams/momentum', momentum, e)\n",
    "#     writer.add_scalar('hyperparams/sigma', sigma, e)\n",
    "#     writer.add_scalar('hyperparams/n_perturbations', n_perturbations, e)\n",
    "\n",
    "## Define Training Loop\n",
    "def training_loop(self, writer, e):    \n",
    "\n",
    "    ### do in every iteration ###\n",
    "    # save current params to calculate update norm\n",
    "    prev_params = torch.nn.utils.parameters_to_vector(self.model.parameters())\n",
    "    #update model\n",
    "    self.utility = self.learner.update_strategy_and_evaluate_utility()\n",
    "    \n",
    "    ## everything after this is logging --> measure overhead\n",
    "    start_time = timer()\n",
    "    \n",
    "    # calculate infinity-norm of update step\n",
    "    new_params = torch.nn.utils.parameters_to_vector(self.model.parameters())\n",
    "    self.update_norm = (new_params - prev_params).norm(float('inf'))    \n",
    "    # calculate utility vs bne    \n",
    "    self.utility_vs_bne = self.bne_env.get_reward(strat_to_bidder(self.model, batch_size = eval_batch_size), draw_valuations=False)\n",
    "    self.epsilon_relative = 1 - self.utility_vs_bne / self.bne_utility\n",
    "    self.epsilon_absolute = self.bne_utility - self.utility_vs_bne\n",
    "    \n",
    "    self.log_metrics(writer, e)\n",
    "    \n",
    "    if e % self._logging_options['plot_epoch'] == 0:\n",
    "        # plot current function output\n",
    "        #bidder = strat_to_bidder(model, batch_size)\n",
    "        #bidder.draw_valuations_()\n",
    "        v = self.bidders[0].valuations\n",
    "        b = self.bidders[0].get_action()\n",
    "        plot_data = (v,b)\n",
    "\n",
    "        print(\"Epoch {}: \\tcurrent utility: {:.3f},\\t utility vs BNE: {:.3f}, \\tepsilon (abs/rel): ({:.5f}, {:.5f})\".format(\n",
    "            e, self.utility, self.utility_vs_bne, self.epsilon_absolute, self.epsilon_relative))\n",
    "        self.plot(self.fig, plot_data ,writer,e)\n",
    "            \n",
    "    elapsed = timer() - start_time        \n",
    "    self.overhead_mins = self.overhead_mins + elapsed/60\n",
    "    writer.add_scalar('debug/overhead_mins', self.overhead_mins, e)\n",
    "    \n",
    "# Define Experiment Class\n",
    "class SymmetricSingleItemAuctionExperiment(Experiment):\n",
    "    setup_players = setup_bidders\n",
    "    setup_learning_environment = setup_learning_environment\n",
    "    setup_learners = setup_learner\n",
    "    equilibrium_strategy = optimal_bid\n",
    "    setup_eval_environment = setup_eval_environment\n",
    "    plot = plot_bid_function\n",
    "    log_once = log_once\n",
    "    log_metrics = log_metrics\n",
    "    log_hyperparams = log_hyperparams\n",
    "    training_loop = training_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create the experiment\n",
    "### THIS IS WHERE FIRST RANDOM THINGS HAPPEN. Set Seed\n",
    "\n",
    "exp = SymmetricSingleItemAuctionExperiment(   \n",
    "    name = ['single_item', auction_mechanism, valuation_prior, 'symmetric', str(n_players)+'p'],\n",
    "    mechanism = mechanism,\n",
    "    n_players = n_players,\n",
    "    logging_options = logging_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check setup\n",
    "\n",
    "print(exp.model)\n",
    "n_parameters = sum([p.numel() for p in exp.model.parameters()])\n",
    "print('Total parameters: ' + str(n_parameters))\n",
    "\n",
    "\n",
    "\n",
    "# when calculating utilities, make sure valuations are drawn at least once.\n",
    "print(\"Utility in BNE (analytical): \\t{:.5f}\".format(exp.bne_utility))\n",
    "print('Utility in BNE (sampled): \\t{:.5f}'.format(\n",
    "    exp.bne_env.get_reward(exp.bne_env.agents[0], draw_valuations=True)))\n",
    "print('Model utility vs BNE: \\t\\t{:.5f}'.format(\n",
    "    exp.bne_env.get_strategy_reward(exp.model, player_position=0)))\n",
    "print('Model utility in learning env:\\t{:.5f}'.format(\n",
    "    exp.env.get_strategy_reward(exp.model, player_position=0, draw_valuations = True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.memory_allocated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.run(epochs, run_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.memory_allocated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del exp\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.ipc_collect()\n",
    "torch.cuda.memory_allocated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
