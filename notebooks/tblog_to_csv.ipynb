{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from collections import defaultdict\n",
    "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.path.abspath('.'))\n",
    "# tflog_dir must be the directory immediately above the runs and each run must have the same shape. No aggregation of multiple subdirectories for now.\n",
    "tflog_dir = './fpsb/asymmetric/uniform/2p' # where to find the runs to aggregate\n",
    "output_dir = tflog_dir                 # where to writethe output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on https://stackoverflow.com/a/57411105/4755970\n",
    "def tabulate_events(dpath):\n",
    "\n",
    "    final_out = {}\n",
    "    \n",
    "    # runs are all subdirectories that don't start with '.' (exclude '.ipython_checkpoints')\n",
    "    # add more filters as needed\n",
    "    runs = [x.name for x in os.scandir(dpath) if x.is_dir() and not x.name.startswith('.')]\n",
    "    \n",
    "    for dname in runs:\n",
    "        print(f\"Converting run {dname}\",end=\"\")\n",
    "        ea = EventAccumulator(os.path.join(dpath, dname)).Reload()\n",
    "        tags = ea.Tags()['scalars']\n",
    "\n",
    "        out = {}\n",
    "\n",
    "        for tag in tags:\n",
    "            tag_values=[]\n",
    "            wall_time=[]\n",
    "            steps=[]\n",
    "\n",
    "            for event in ea.Scalars(tag):\n",
    "                tag_values.append(event.value)\n",
    "                wall_time.append(event.wall_time)\n",
    "                steps.append(event.step)\n",
    "\n",
    "            out[tag]=pd.DataFrame(data=dict(zip(steps,np.array([tag_values,wall_time]).transpose())), columns=steps,index=['value','wall_time'])\n",
    "\n",
    "        if len(tags)>0:      \n",
    "            df= pd.concat(out.values(),keys=out.keys())\n",
    "            df.to_csv(os.path.join(output_dir, f'result_{dname}.csv'))\n",
    "            print(\"- Done\")\n",
    "        else:\n",
    "            print('- Not scalers to write')\n",
    "            \n",
    "        final_out[dname] = df\n",
    "        \n",
    "    return final_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    steps = tabulate_events(tflog_dir)\n",
    "    pd.concat(steps.values(),keys=steps.keys()).to_csv(os.path.join(output_dir, 'all_results.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
