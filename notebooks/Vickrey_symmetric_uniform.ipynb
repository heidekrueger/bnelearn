{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# n Player Vickrey Auction with uniform symmetric valuation distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, time, warnings\n",
    "root_path = os.path.abspath(os.path.join('..'))\n",
    "if root_path not in sys.path:\n",
    "    sys.path.append(root_path)\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils as ut\n",
    "from torch.optim.optimizer import Optimizer, required\n",
    "\n",
    "from bnelearn.strategy import NeuralNetStrategy, ClosureStragegy\n",
    "from bnelearn.bidder import Bidder\n",
    "from bnelearn.mechanism import FirstPriceSealedBidAuction, VickreyAuction\n",
    "from bnelearn.optimizer import ES\n",
    "from bnelearn.environment import AuctionEnvironment\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set up matplotlib\n",
    "is_ipython = 'inline' in plt.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "#\n",
    "#plt.ion()\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "device = 'cuda' if cuda else 'cpu'\n",
    "\n",
    "# Use specific cuda gpu if desired (i.e. for running multiple experiments in parallel)\n",
    "specific_gpu = 1\n",
    "if cuda and specific_gpu:\n",
    "    torch.cuda.set_device(specific_gpu)\n",
    "\n",
    "print(device)\n",
    "if cuda: print(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings\n",
    "\n",
    "The following cell fully defines an experiment.\n",
    "The following set of parameters works well:\n",
    "```\n",
    "2p:  ?\n",
    "\n",
    "\n",
    "3p: (run 2019-07-08 Mon 10:37)\n",
    "    batch_size = 2**17, size_hidden_layer = 10, learning_rate = 3.5e-1, lr_decay_every = 1000, lr_decay_factor = 0.75, momentum = 0.7, sigma = .02, n_perturbations = 64,\n",
    "    eval_batch_size 2**25\n",
    "    (1 hidden layer, tanh)\n",
    "    \n",
    "10p: (run 2019-07-08 Mon 13:57 shows settings for 3p above are not aggressive enough --> need higher step sizes.)\n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_comment = '' # used in log title\n",
    "resume = False\n",
    "\n",
    "## Experiment setup\n",
    "n_players = 10\n",
    "n_items = 1\n",
    "\n",
    "# valuation distribution\n",
    "u_lo =0\n",
    "u_hi =10\n",
    "\n",
    "## Environment settings\n",
    "#training batch size\n",
    "batch_size = 2**17\n",
    "input_length = 1\n",
    "\n",
    "eval_batch_size = 2**25\n",
    "\n",
    "# strategy model architecture\n",
    "size_hidden_layer = 10\n",
    "\n",
    "# optimization params\n",
    "epoch = 15000\n",
    "learning_rate = 3.5e-1\n",
    "lr_decay = True\n",
    "lr_decay_every = 1000\n",
    "lr_decay_factor = 0.75\n",
    "momentum = 0.7\n",
    "\n",
    "sigma = .02 #ES noise parameter\n",
    "n_perturbations = 64\n",
    "\n",
    "# plot and log training options\n",
    "plot_epoch = 100\n",
    "plot_points = min(100, batch_size)\n",
    "\n",
    "plot_xmin = u_lo\n",
    "plot_xmax = u_hi\n",
    "plot_ymin = 0\n",
    "plot_ymax = 10\n",
    "\n",
    "\n",
    "def strat_to_bidder(strategy, batch_size=batch_size, player_position=None, cache_actions=False):\n",
    "    return Bidder.uniform(u_lo, u_hi, strategy,\n",
    "                          batch_size = batch_size,\n",
    "                          player_position=player_position,\n",
    "                          cache_actions=cache_actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When initializing the model, we'll ensure the initialization provides positive outputs on the domain we are interested in, as otherwise we can't learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mechanism = VickreyAuction(cuda = True)\n",
    "\n",
    "output_is_positive = False\n",
    "while not output_is_positive:\n",
    "    model = NeuralNetStrategy(input_length,\n",
    "                              size_hidden_layer = size_hidden_layer,\n",
    "                              requires_grad=False\n",
    "                             ).to(device)\n",
    "    \n",
    "    if model(torch.tensor([float(u_hi)], device=device)) > 0:\n",
    "        output_is_positive = True    \n",
    "        \n",
    "\n",
    "env = AuctionEnvironment(mechanism,\n",
    "                  agents = [], #dynamically built\n",
    "                  max_env_size = n_players - 1, #\n",
    "                  batch_size = batch_size,\n",
    "                  n_players =n_players,\n",
    "                  strategy_to_bidder_closure = strat_to_bidder\n",
    "                 )\n",
    "optimizer = ES(model=model, environment = env,\n",
    "               lr = learning_rate, momentum=momentum,\n",
    "               sigma=sigma, n_perturbations=n_perturbations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up Evaluation and logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for evaluation\n",
    "def optimal_bid(valuation):\n",
    "    return valuation\n",
    "\n",
    "bneStrategy = ClosureStragegy(optimal_bid)\n",
    "\n",
    "# environment filled with optimal players for logging\n",
    "# use higher batch size for calculating optimum\n",
    "bne_env = AuctionEnvironment(mechanism,\n",
    "                            agents = [strat_to_bidder(bneStrategy,\n",
    "                                                      player_position= i,\n",
    "                                                      batch_size = eval_batch_size,\n",
    "                                                      cache_actions=True)\n",
    "                                      for i in range(n_players)\n",
    "                                     ],\n",
    "                            batch_size = eval_batch_size,\n",
    "                            n_players=n_players,\n",
    "                            strategy_to_bidder_closure = strat_to_bidder\n",
    "                           )\n",
    "\n",
    "bne_utility = bne_env.get_reward(bne_env.agents[0], draw_valuations=True)\n",
    "print('Utility in BNE: \\t\\t{:.5f}'.format(bne_utility))\n",
    "utility_vs_bne = bne_env.get_reward(strat_to_bidder(model, batch_size = eval_batch_size))\n",
    "print('Model utility vs BNE: \\t\\t{:.5f}'.format(utility_vs_bne))\n",
    "utility_learning_env = env.get_reward(strat_to_bidder(model), draw_valuations = True)\n",
    "print('Model utility in learning env:\\t{:.5f}'.format(utility_learning_env))\n",
    "\n",
    "v_opt = np.linspace(plot_xmin, plot_xmax, 100)\n",
    "b_opt = optimal_bid(v_opt)\n",
    "    \n",
    "def plot_bid_function(fig, v,b, writer=None, e=None, plot_points=plot_points):\n",
    "    \n",
    "    # subsample points and plot\n",
    "    v = v.detach().cpu().numpy()[:plot_points]\n",
    "    b= b.detach().cpu().numpy()[:plot_points]\n",
    "    \n",
    "    fig = plt.gcf()\n",
    "    plt.cla()\n",
    "    plt.xlim(plot_xmin, plot_xmax)\n",
    "    plt.ylim(plot_ymin, plot_ymax)\n",
    "    plt.plot(v,b, 'o', v_opt, b_opt, 'r--')\n",
    "    #if is_ipython:\n",
    "        #display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())\n",
    "    if writer:\n",
    "        writer.add_figure('eval/bid_function', fig, e)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_hyperparams(writer, e):\n",
    "    writer.add_scalar('hyperparams/batch_size', batch_size, e)\n",
    "    writer.add_scalar('hyperparams/size_hidden_layer', size_hidden_layer, e)\n",
    "    writer.add_scalar('hyperparams/learning_rate', learning_rate, e)\n",
    "    writer.add_scalar('hyperparams/momentum', momentum, e)\n",
    "    writer.add_scalar('hyperparams/sigma', sigma, e)\n",
    "    writer.add_scalar('hyperparams/n_perturbations', n_perturbations, e)\n",
    "    writer.add_scalar('debug/eval_batch_size', eval_batch_size, e)\n",
    "\n",
    "def training_loop(e, writer):\n",
    "    \n",
    "    global overhead_mins, learning_rate\n",
    "    \n",
    "    if lr_decay and e % lr_decay_every == 0 and e > 0:\n",
    "        learning_rate = learning_rate * lr_decay_factor\n",
    "        log_hyperparams(writer, e)\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = learning_rate\n",
    "\n",
    "    # always: do optimizer step\n",
    "    utility = -optimizer.step()\n",
    "    writer.add_scalar('eval/utility', utility, e)\n",
    "        \n",
    "    utility_vs_bne = bne_env.get_reward(strat_to_bidder(model, batch_size = eval_batch_size), draw_valuations=False)\n",
    "    epsilon_relative = 1 - utility_vs_bne / bne_utility\n",
    "    epsilon_absolute = bne_utility - utility_vs_bne\n",
    "    writer.add_scalar('eval/utility_vs_bne', utility_vs_bne, e)\n",
    "    writer.add_scalar('eval/epsilon_relative', epsilon_relative, e)\n",
    "    writer.add_scalar('debug/epsilon_absolute', epsilon_absolute, e) # debug because only interesting to see if numeric precision is a problem, otherwise same as relative but scaled.\n",
    "\n",
    "    if e % plot_epoch == 0:\n",
    "        start_time = timer()\n",
    "        # plot current function output\n",
    "        bidder = strat_to_bidder(model, batch_size)\n",
    "        bidder.draw_valuations_()\n",
    "        v = bidder.valuations\n",
    "        b = bidder.get_action()\n",
    "        #share = b.mean()/optimal_bid(v).mean()\n",
    "        #diff = (b-optimal_bid(v)).mean()\n",
    "        #writer.add_scalar('eval/share', share, e)\n",
    "        #writer.add_scalar('eval/diff', diff, e)\n",
    "        writer.add_graph(model, bidder.valuations) \n",
    "\n",
    "        print(\"Epoch {}: \\tcurrent utility: {:.3f},\\t utility vs BNE: {:.3f}, \\tepsilon (abs/rel): ({:.5f}, {:.5f})\".format(e, utility, utility_vs_bne, epsilon_absolute, epsilon_relative))\n",
    "        plot_bid_function(fig, v,b,writer,e)\n",
    "            \n",
    "        elapsed = timer() - start_time\n",
    "            \n",
    "        overhead_mins = overhead_mins + elapsed/60\n",
    "        writer.add_scalar('debug/overhead_mins', overhead_mins, e)\n",
    "            \n",
    "        print(\"Logging checkpoint took {:.2f}s.\".format(elapsed))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if not 'resume' in locals() or not resume:\n",
    "#    e = 0\n",
    "#    overhead_mins = 0\n",
    "\n",
    "# setup logger\n",
    "if os.name == 'nt': raise ValueError('The run_name may not contain : on Windows! (change datetime format to fix this)') \n",
    "run_name = time.strftime('%Y-%m-%d %a %H:%M')\n",
    "if run_comment:\n",
    "    run_name = run_name + ' - ' + str(run_comment)\n",
    "logdir = os.path.join(root_path, 'notebooks', 'vickrey', str(n_players) + 'p', 'uniform', 'symmetric', run_name)\n",
    "\n",
    "e = 0\n",
    "overhead_mins = 0\n",
    "\n",
    "print(logdir)\n",
    "fig = plt.figure()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "with SummaryWriter(logdir, flush_secs=30) as writer:\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    log_hyperparams(writer, 0)    \n",
    "    \n",
    "    for e in range(e,e+epoch+1):\n",
    "        training_loop(e, writer)       \n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
