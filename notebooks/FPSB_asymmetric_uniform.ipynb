{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Player FPSB Auction with assymetric uniform valuation distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "root_path = os.path.abspath(os.path.join('..'))\n",
    "if root_path not in sys.path:\n",
    "    sys.path.append(root_path)\n",
    "import time\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils as ut\n",
    "from torch.optim.optimizer import Optimizer, required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bnelearn.strategy import NeuralNetStrategy, TruthfulStrategy\n",
    "from bnelearn.bidder import Bidder\n",
    "from bnelearn.mechanism import FirstPriceSealedBidAuction, VickreyAuction\n",
    "from bnelearn.optimizer import ES\n",
    "from bnelearn.environment import AuctionEnvironment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set up matplotlib\n",
    "is_ipython = 'inline' in plt.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "#\n",
    "#plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = torch.cuda.is_available()\n",
    "device = 'cuda' if cuda else 'cpu'\n",
    "\n",
    "# Use specific cuda gpu if desired (i.e. for running multiple experiments in parallel)\n",
    "specific_gpu = 7\n",
    "if cuda and specific_gpu:\n",
    "    torch.cuda.set_device(specific_gpu)\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_comment = ''\n",
    "\n",
    "## Experiment setup\n",
    "n_players = 2\n",
    "n_items = 1\n",
    "# valuation distribution\n",
    "# both players should have same lower bound\n",
    "u_lo =   5.\n",
    "u1_hi = 15.\n",
    "u2_hi = 20.\n",
    "\n",
    "def strat_to_bidder(strategy, batch_size, u_hi, player_position=None):\n",
    "    return Bidder.uniform(u_lo, u_hi, strategy, player_position=player_position, batch_size = batch_size)\n",
    "\n",
    "## Environment settings\n",
    "#training batch size\n",
    "batch_size = 2**16\n",
    "input_length = 1\n",
    "\n",
    "# strategy model architecture\n",
    "size_hidden_layer = 10\n",
    "\n",
    "# optimization params\n",
    "epoch = 5000\n",
    "learning_rate = 2e-1\n",
    "lr_decay = False\n",
    "lr_decay_every = 2000\n",
    "lr_decay_factor = 0.8\n",
    "baseline = True\n",
    "momentum = 0.6\n",
    "\n",
    "sigma = .02 #ES noise parameter\n",
    "n_perturbations = 128\n",
    "\n",
    "# plot and log training options\n",
    "plot_epoch = 250\n",
    "plot_points = min(100, batch_size)\n",
    "\n",
    "plot_xmin = u_lo\n",
    "plot_xmax = u2_hi\n",
    "plot_ymin = 0\n",
    "plot_ymax = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for evaluation\n",
    "# helper constant\n",
    "c = 1 / (u1_hi - u_lo)**2 - 1 / (u2_hi - u_lo)**2\n",
    "def optimal_bid(valuation: torch.Tensor or np.ndarray or float,\n",
    "                player_position: int) -> torch.Tensor:\n",
    "    #print(c)\n",
    "    \n",
    "    if not isinstance(valuation, torch.Tensor):\n",
    "        valuation = torch.tensor(valuation, dtype=torch.float)\n",
    "    #unsqueeze if simple float\n",
    "    if valuation.dim() == 0:\n",
    "        valuation.unsqueeze_(0)\n",
    "    \n",
    "    if player_position == 1:\n",
    "        return u_lo + (valuation - u_lo) / (1 + torch.sqrt(1 - c*(valuation - u_lo)**2))\n",
    "    elif player_position == 2:\n",
    "        return u_lo + (valuation - u_lo) / (1 + torch.sqrt(1 + c*(valuation - u_lo)**2))\n",
    "            \n",
    "\n",
    "def log_hyperparams(writer, e):\n",
    "    writer.add_scalar('hyperparams/batch_size', batch_size, e)\n",
    "    writer.add_scalar('hyperparams/size_hidden_layer', size_hidden_layer, 0)\n",
    "    writer.add_scalar('hyperparams/learning_rate', learning_rate, e)\n",
    "    writer.add_scalar('hyperparams/momentum', momentum, e)\n",
    "    writer.add_scalar('hyperparams/sigma', sigma, e)\n",
    "    writer.add_scalar('hyperparams/n_perturbations', n_perturbations, e)\n",
    "\n",
    "v1_opt = np.linspace(u_lo, u1_hi, 25)\n",
    "b1_opt = optimal_bid(v1_opt, 1).numpy()\n",
    "v2_opt = np.linspace(u_lo, u2_hi, 50)\n",
    "b2_opt = optimal_bid(v2_opt, 2).numpy()\n",
    "    \n",
    "def plot_bid_function(fig, v1,b1, v2, b2, writer=None, e=None, plot_points=plot_points):\n",
    "    #plot_points = min(plot_points, len(v1), len(v2))\n",
    "    \n",
    "    # subsample points and plot    \n",
    "    v1 = v1.detach().cpu().numpy()[:plot_points]\n",
    "    b1 = b1.detach().cpu().numpy()[:plot_points]\n",
    "    v2 = v2.detach().cpu().numpy()[:plot_points]\n",
    "    b2 = b2.detach().cpu().numpy()[:plot_points]\n",
    "    \n",
    "    fig = plt.gcf()\n",
    "    plt.cla()\n",
    "    plt.xlim(plot_xmin, plot_xmax)\n",
    "    plt.ylim(plot_ymin, plot_ymax)\n",
    "    plt.plot(v1,b1, 'bo', v1_opt, b1_opt, 'b--', v2,b2, 'ro', v2_opt,b2_opt, 'r--')\n",
    "    #if is_ipython:\n",
    "        #display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())\n",
    "    if writer:\n",
    "        writer.add_figure('eval/bid_function', fig, e)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the model.\n",
    "We'll ensure the initialization provides positive outputs on the domain we are interested in, as otherwise we can't learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize models\n",
    "model_1 = NeuralNetStrategy(input_length,\n",
    "                            size_hidden_layer = size_hidden_layer,\n",
    "                            requires_grad=False,\n",
    "                            ensure_positive_output = torch.tensor([float(u1_hi)])\n",
    "                            ).to(device)\n",
    "   \n",
    "\n",
    "model_2 = NeuralNetStrategy(input_length,\n",
    "                            size_hidden_layer = size_hidden_layer,\n",
    "                            requires_grad=False,\n",
    "                            ensure_positive_output = torch.tensor([float(u2_hi)])\n",
    "                            ).to(device)\n",
    "\n",
    "bidder_1 = strat_to_bidder(model_1, batch_size, u1_hi, player_position=0)\n",
    "bidder_2 = strat_to_bidder(model_2, batch_size, u2_hi, player_position=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mechanism = FirstPriceSealedBidAuction(cuda = True)\n",
    "env = AuctionEnvironment(mechanism,\n",
    "                  agents = [bidder_1, bidder_2],\n",
    "                  batch_size = batch_size,\n",
    "                  n_players =n_players,\n",
    "                  strategy_to_bidder_closure = strat_to_bidder\n",
    "                 )\n",
    "optimizer_1 = ES(model=model_1, environment = env,\n",
    "                 lr = learning_rate, momentum=momentum,\n",
    "                 sigma=sigma, n_perturbations=n_perturbations, baseline=baseline,\n",
    "                 strat_to_player_kwargs={\"player_position\":0, \"u_hi\": u1_hi}\n",
    "                )\n",
    "optimizer_2 = ES(model=model_2, environment = env,\n",
    "                 lr = learning_rate, momentum=momentum,\n",
    "                 sigma=sigma, n_perturbations=n_perturbations, baseline=baseline,\n",
    "                 strat_to_player_kwargs={\"player_position\":1,\"u_hi\": u2_hi}\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.name == 'nt': raise ValueError('The run_name may not contain : on Windows! (change datetime format to fix this)') \n",
    "run_name = time.strftime('%Y-%m-%d %a %H:%M')\n",
    "if run_comment:\n",
    "    run_name = run_name + ' - ' + str(run_comment)\n",
    "logdir = os.path.join(root_path, 'notebooks', 'fpsb', str(n_players) + 'p', 'uniform', 'asymmetric', run_name)\n",
    "\n",
    "\n",
    "with SummaryWriter(logdir, flush_secs=60) as writer:\n",
    "    \n",
    "    # create custom_scalar multilinechart with both player's utilities\n",
    "    ## NOTE: this does not work in pytorch 1.1.0 due to a bug, fixed pytorch-nightly (and will be in 1.2.0 stable)\n",
    "    # uncomment once 1.2 is available -- see issue #18 https://gitlab.lrz.de/heidekrueger/bnelearn/issues/18\n",
    "    #writer.add_custom_scalars(torch.utils.tensorb['eval/p1_utility', 'eval/p2_utility'], title = 'Player Utilities')\n",
    "    \n",
    "    overhead_mins = 0\n",
    "    torch.cuda.empty_cache()\n",
    "    log_hyperparams(writer, 0)\n",
    "    fig = plt.figure()\n",
    "    for e in range(epoch+1):\n",
    "        # lr decay?\n",
    "        if lr_decay and e % lr_decay_every == 0 and e > 0:\n",
    "            learning_rate = learning_rate * lr_decay_factor\n",
    "            log_hyperparams(writer, e)\n",
    "            for param_group in optimizer_1.param_groups:\n",
    "                param_group['lr'] = learning_rate\n",
    "\n",
    "        # always: do optimizer step\n",
    "        utility_1 = -optimizer_1.step()\n",
    "        writer.add_scalar('eval/p1_utility', utility_1, e)\n",
    "        utility_2 = -optimizer_2.step()\n",
    "        writer.add_scalar('eval/p2_utility', utility_2, e)\n",
    "\n",
    "        if e % plot_epoch == 0:\n",
    "            start_time = timer()\n",
    "            # plot current function output\n",
    "            bidder_1.draw_valuations_()\n",
    "            v_1 = bidder_1.valuations\n",
    "            b_1 = bidder_1.get_action()\n",
    "            bidder_2.draw_valuations_()\n",
    "            v_2 = bidder_2.valuations\n",
    "            b_2 = bidder_2.get_action()\n",
    "            \n",
    "            #share = b.mean()/optimal_bid(v).mean()\n",
    "            #diff = (b-optimal_bid(v)).mean()\n",
    "            #writer.add_scalar('eval/share', share, e)\n",
    "            #writer.add_scalar('eval/diff', diff, e)\n",
    "            writer.add_graph(model_1, bidder_1.valuations) \n",
    "\n",
    "            print(\"Epoch {}: \\tutilities: \\t p1: {:.3f} \\t p2: {:.3f}\".format(e, utility_1, utility_2))\n",
    "            plot_bid_function(fig, v_1, b_1, v_2, b_2, writer,e)\n",
    "            \n",
    "            elapsed = timer() - start_time\n",
    "            overhead_mins = overhead_mins + elapsed/60\n",
    "            writer.add_scalar('debug/overhead_mins', overhead_mins, e)\n",
    "            \n",
    "            print(\"Logging checkpoint took {:.2f}s.\".format(elapsed))         \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
