{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Player FPSB Auction with assymetric uniform valuation distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "root_path = os.path.abspath(os.path.join('..'))\n",
    "if root_path not in sys.path:\n",
    "    sys.path.append(root_path)\n",
    "import time\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils as ut\n",
    "from torch.optim.optimizer import Optimizer, required\n",
    "\n",
    "from bnelearn.strategy import NeuralNetStrategy, ClosureStrategy\n",
    "from bnelearn.bidder import Bidder\n",
    "from bnelearn.mechanism import FirstPriceSealedBidAuction, VickreyAuction\n",
    "from bnelearn.optimizer import ES\n",
    "from bnelearn.environment import AuctionEnvironment\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set up matplotlib\n",
    "is_ipython = 'inline' in plt.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "plt.rcParams['figure.figsize'] = [8, 5]\n",
    "    \n",
    "cuda = torch.cuda.is_available()\n",
    "device = 'cuda' if cuda else 'cpu'\n",
    "\n",
    "# Use specific cuda gpu if desired (i.e. for running multiple experiments in parallel)\n",
    "specific_gpu = 7\n",
    "if cuda and specific_gpu:\n",
    "    torch.cuda.set_device(specific_gpu)\n",
    "\n",
    "print(device)\n",
    "if cuda: print(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log in notebook folder\n",
    "# alternative for shared access to experiments:\n",
    "# log_root = os.path.abspath('/srv/bnelearn-experiments/')\n",
    "log_root = os.path.abspath('.')\n",
    "run_comment = ''\n",
    "\n",
    "## Experiment setup\n",
    "n_players = 2\n",
    "n_items = 1\n",
    "# valuation distribution\n",
    "# both players should have same lower bound\n",
    "u_lo =   5.\n",
    "u1_hi = 15.\n",
    "u2_hi = 25.\n",
    "u_his = [u1_hi, u2_hi]\n",
    "\n",
    "def strat_to_bidder(strategy, batch_size, player_position):\n",
    "    return Bidder.uniform(u_lo, u_his[player_position], strategy, player_position=player_position, batch_size = batch_size)\n",
    "\n",
    "## Environment settings\n",
    "#training batch size\n",
    "batch_size = 2**16\n",
    "eval_batch_size = 2**25\n",
    "\n",
    "# strategy model architecture\n",
    "input_length = 1\n",
    "hidden_nodes = [5, 5]\n",
    "hidden_activations = [nn.SELU(), nn.SELU()]\n",
    "\n",
    "# optimization params\n",
    "epoch = 5000\n",
    "learning_rate = 2e-1\n",
    "lr_decay = False\n",
    "lr_decay_every = 1000\n",
    "lr_decay_factor = 0.5\n",
    "baseline = True\n",
    "momentum = 0.6\n",
    "\n",
    "sigma = .02 #ES noise parameter\n",
    "n_perturbations = 64\n",
    "\n",
    "# plot and log training options\n",
    "plot_epoch = 50\n",
    "plot_points = min(100, batch_size)\n",
    "\n",
    "plot_xmin = u_lo\n",
    "plot_xmax = u2_hi\n",
    "plot_ymin = 0\n",
    "plot_ymax = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For $v_1 \\sim U(\\alpha, \\beta_1)$, $v_2 \\sim U(\\alpha, \\beta_2)$, and with\n",
    "\n",
    "$$c = \\frac{1}{(\\beta_1 - \\alpha)²} -\\frac{1}{(\\beta_2 - \\alpha)²}, $$\n",
    "\n",
    "the equilibrium bids are given by\n",
    "\n",
    "$$b_1^*(v_1) = \\alpha + \\frac{v_1 - \\alpha}{1 + \\sqrt{1-c(v_1-\\alpha)²}} $$\n",
    "\n",
    "$$b_2^*(v_2) = \\alpha + \\frac{v_2 - \\alpha}{1 + \\sqrt{1-c(v_2-\\alpha)²}} $$\n",
    "\n",
    "(See https://link.springer.com/article/10.1007/BF01271133\n",
    "\n",
    "The expected utility in the bne can then be calculated using\n",
    "\n",
    "$$E[u_{BNE}] = \\int_{0}^{\\infty}{P(win | b) * u(b,v | win) *f(v) dv} = ???$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for evaluation\n",
    "# helper constant\n",
    "c = 1 / (u1_hi - u_lo)**2 - 1 / (u2_hi - u_lo)**2\n",
    "def optimal_bid(valuation: torch.Tensor or np.ndarray or float,\n",
    "                player_position: int) -> torch.Tensor:\n",
    "    #print(c)\n",
    "    \n",
    "    if not isinstance(valuation, torch.Tensor):\n",
    "        valuation = torch.tensor(valuation, dtype=torch.float)\n",
    "    #unsqueeze if simple float\n",
    "    if valuation.dim() == 0:\n",
    "        valuation.unsqueeze_(0)\n",
    "    \n",
    "    if player_position == 0:\n",
    "        # weak player\n",
    "        return u_lo + (valuation - u_lo) / (1 + torch.sqrt(1 - c*(valuation - u_lo)**2))\n",
    "    elif player_position == 1:\n",
    "        # strong player\n",
    "        return u_lo + (valuation - u_lo) / (1 + torch.sqrt(1 + c*(valuation - u_lo)**2))\n",
    "\n",
    "\n",
    "def log_once(writer, e):\n",
    "    \"\"\"Everything that should be logged only once on initialization.\"\"\"\n",
    "    writer.add_scalar('debug/total_model_parameters', n_parameters, e)\n",
    "    writer.add_scalar('debug/eval_batch_size', eval_batch_size, e)\n",
    "    writer.add_text('hyperparams/neural_net_spec', str(model_1), 0)    \n",
    "    #writer.add_scalar('debug/eval_batch_size', eval_batch_size, e)\n",
    "    writer.add_graph(model_1, env.agents[0].valuations)    \n",
    "\n",
    "def log_hyperparams(writer, e):\n",
    "    writer.add_scalar('hyperparams/batch_size', batch_size, e)\n",
    "    writer.add_scalar('hyperparams/batch_size', batch_size, e)\n",
    "    writer.add_scalar('hyperparams/learning_rate', learning_rate, e)\n",
    "    writer.add_scalar('hyperparams/momentum', momentum, e)\n",
    "    writer.add_scalar('hyperparams/sigma', sigma, e)\n",
    "    writer.add_scalar('hyperparams/n_perturbations', n_perturbations, e)\n",
    "    \n",
    "    \n",
    "def log_utilities_per_player(global_writer, player_writers, u, u_vs_bne, e):\n",
    "    \"\"\"log scalar for each player. Tensor should be of shape n_players\"\"\"\n",
    "    \n",
    "    epsilons_rel = eps_rel(u_vs_bne)\n",
    "    epsilons_abs = eps_abs(u_vs_bne)\n",
    "    \n",
    "    for i,w in enumerate(player_writers):\n",
    "        w.add_scalar('eval/utility', u[i], e)\n",
    "        w.add_scalar('eval/utility_vs_bne', u_vs_bne[i], e)\n",
    "        w.add_scalar('debug/epsilon_absolute', epsilons_abs[i], e)\n",
    "        w.add_scalar('eval/epsilon_relative', epsilons_rel[i], e)\n",
    "    \n",
    "    global_writer.add_scalar('eval/epsilon_relative', epsilons_rel.mean(),e)\n",
    "    global_writer.add_scalar('debug/epsilon_absolute', epsilons_abs.mean(),e)\n",
    "\n",
    "v1_opt = np.linspace(u_lo, u1_hi, 25)\n",
    "b1_opt = optimal_bid(v1_opt, 0).numpy()\n",
    "v2_opt = np.linspace(u_lo, u2_hi, 50)\n",
    "b2_opt = optimal_bid(v2_opt, 1).numpy()\n",
    "    \n",
    "def plot_bid_function(fig, v1,b1, v2, b2, writer=None, e=None, plot_points=plot_points):\n",
    "    #plot_points = min(plot_points, len(v1), len(v2))\n",
    "    \n",
    "    # subsample points and plot    \n",
    "    v1 = v1.detach().cpu().numpy()[:plot_points]\n",
    "    b1 = b1.detach().cpu().numpy()[:plot_points]\n",
    "    v2 = v2.detach().cpu().numpy()[:plot_points]\n",
    "    b2 = b2.detach().cpu().numpy()[:plot_points]\n",
    "    \n",
    "    fig = plt.gcf()\n",
    "    plt.cla()\n",
    "    plt.xlim(plot_xmin, plot_xmax)\n",
    "    plt.ylim(plot_ymin, plot_ymax)\n",
    "    plt.plot(v1,b1, 'bo', v1_opt, b1_opt, 'b--', v2,b2, 'ro', v2_opt,b2_opt, 'r--')\n",
    "    #if is_ipython:\n",
    "        #display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())\n",
    "    if writer:\n",
    "        writer.add_figure('eval/bid_function', fig, e)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the model.\n",
    "We'll ensure the initialization provides positive outputs on the domain we are interested in, as otherwise we can't learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize models\n",
    "model_1 = NeuralNetStrategy(input_length,                            \n",
    "                            hidden_nodes = hidden_nodes,\n",
    "                            hidden_activations = hidden_activations,\n",
    "                            requires_grad=False,\n",
    "                            ensure_positive_output = torch.tensor([float(u1_hi)])\n",
    "                            ).to(device)\n",
    "   \n",
    "\n",
    "model_2 = NeuralNetStrategy(input_length,\n",
    "                            hidden_nodes = hidden_nodes,\n",
    "                            hidden_activations = hidden_activations,\n",
    "                            requires_grad=False,\n",
    "                            ensure_positive_output = torch.tensor([float(u2_hi)])\n",
    "                            ).to(device)\n",
    "\n",
    "bidder_1 = strat_to_bidder(model_1, batch_size, player_position=0)\n",
    "bidder_2 = strat_to_bidder(model_2, batch_size, player_position=1)\n",
    "\n",
    "mechanism = FirstPriceSealedBidAuction(cuda = True)\n",
    "env = AuctionEnvironment(mechanism,\n",
    "                  agents = [bidder_1, bidder_2],\n",
    "                  batch_size = batch_size,\n",
    "                  n_players =n_players,\n",
    "                  strategy_to_player_closure = strat_to_bidder\n",
    "                 )\n",
    "optimizer_1 = ES(model=model_1, environment = env,\n",
    "                 lr = learning_rate, momentum=momentum,\n",
    "                 sigma=sigma, n_perturbations=n_perturbations, baseline=baseline,\n",
    "                 strat_to_player_kwargs={\"player_position\":0}\n",
    "                )\n",
    "optimizer_2 = ES(model=model_2, environment = env,\n",
    "                 lr = learning_rate, momentum=momentum,\n",
    "                 sigma=sigma, n_perturbations=n_perturbations, baseline=baseline,\n",
    "                 strat_to_player_kwargs={\"player_position\":1}\n",
    "                )\n",
    "\n",
    "print(model_1)\n",
    "n_parameters = sum([p.numel() for p in model_1.parameters()])\n",
    "print('Total parameters: ' + str(n_parameters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up equilibrium-environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bne_strategies = [\n",
    "    ClosureStrategy(partial(optimal_bid, player_position=i))\n",
    "    for i in range(n_players)\n",
    "]\n",
    "\n",
    "bne_env = AuctionEnvironment(\n",
    "    mechanism,\n",
    "    agents = [strat_to_bidder(bne_strategies[i], player_position=i, batch_size=eval_batch_size)\n",
    "              for i in range(n_players)],\n",
    "    n_players = n_players,\n",
    "    batch_size = eval_batch_size,\n",
    "    strategy_to_player_closure = strat_to_bidder\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "#print(\"Utility in BNE (analytical): \\t{:.5f}\".format(bne_utility))\n",
    "bne_utilities_sampled = torch.tensor([bne_env.get_reward(a, draw_valuations = True) for a in bne_env.agents])\n",
    "print(('Utilities in BNE (sampled):'+ '\\t{:.5f}'*n_players + '.').format(*bne_utilities_sampled))\n",
    "\n",
    "eps_abs = lambda us: bne_utilities_sampled - us\n",
    "eps_rel = lambda us: 1- us/bne_utilities_sampled\n",
    "\n",
    "utilities_vs_bne = torch.tensor([bne_env.get_strategy_reward(a.strategy, player_position=i) for i,a in enumerate(env.agents)])\n",
    "print(('Model utility vs BNE: \\t'+'\\t{:.5f}'*n_players).format(*utilities_vs_bne))\n",
    "\n",
    "utilities_learning_env = torch.tensor([env.get_strategy_reward(a.strategy, player_position=i, draw_valuations = True) for i,a in enumerate(env.agents)])\n",
    "print(('Model utility in learning env:'+'\\t{:.5f}'*n_players).format(*utilities_learning_env))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.name == 'nt': raise ValueError('The run_name may not contain : on Windows! (change datetime format to fix this)') \n",
    "run_name = time.strftime('%Y-%m-%d %a %H:%M')\n",
    "if run_comment:\n",
    "    run_name = run_name + ' - ' + str(run_comment)\n",
    "logdir = os.path.join(root_path, 'notebooks', 'asymmetric_fpsb', str(n_players) + 'p', 'uniform', run_name)\n",
    "print(logdir)\n",
    "\n",
    "\n",
    "with SummaryWriter(logdir, flush_secs=60) as writer,\\\n",
    "     SummaryWriter(os.path.join(logdir, 'player0')) as writer_1, \\\n",
    "     SummaryWriter(os.path.join(logdir, 'player1')) as writer_2:\n",
    "    \n",
    "    player_writers = [writer_1, writer_2]\n",
    "    \n",
    "    # create custom_scalar multilinechart with both player's utilities\n",
    "    ## NOTE: this does not work in pytorch 1.1.0 due to a bug, fixed pytorch-nightly (and will be in 1.2.0 stable)\n",
    "    # uncomment once 1.2 is available -- see issue #18 https://gitlab.lrz.de/heidekrueger/bnelearn/issues/18\n",
    "    #writer.add_custom_scalars(torch.utils.tensorb['eval/p1_utility', 'eval/p2_utility'], title = 'Player Utilities')\n",
    "    \n",
    "    overhead_mins = 0\n",
    "    torch.cuda.empty_cache()\n",
    "    log_once(writer, 0)\n",
    "    log_hyperparams(writer, 0)\n",
    "    fig = plt.figure()\n",
    "    for e in range(epoch+1):\n",
    "        # lr decay?\n",
    "        if lr_decay and e % lr_decay_every == 0 and e > 0:\n",
    "            learning_rate = learning_rate * lr_decay_factor\n",
    "            log_hyperparams(writer, e)\n",
    "            for param_group in optimizer_1.param_groups:\n",
    "                param_group['lr'] = learning_rate\n",
    "\n",
    "        # always: do optimizer step\n",
    "        utility_1 = -optimizer_1.step()\n",
    "        utility_2 = -optimizer_2.step() \n",
    "        \n",
    "        #logging \n",
    "        start_time = timer()\n",
    "        utilities = torch.tensor([utility_1, utility_2])\n",
    "        utilities_vs_bne = torch.tensor([bne_env.get_strategy_reward(a.strategy, player_position=i) for i,a in enumerate(env.agents)])\n",
    "        log_utilities_per_player(writer, player_writers, utilities, utilities_vs_bne, e)\n",
    "\n",
    "        if e % plot_epoch == 0:\n",
    "            \n",
    "            # plot current function output\n",
    "            bidder_1.draw_valuations_()\n",
    "            v_1 = bidder_1.valuations\n",
    "            b_1 = bidder_1.get_action()\n",
    "            bidder_2.draw_valuations_()\n",
    "            v_2 = bidder_2.valuations\n",
    "            b_2 = bidder_2.get_action()\n",
    "            \n",
    "            #share = b.mean()/optimal_bid(v).mean()\n",
    "            #diff = (b-optimal_bid(v)).mean()\n",
    "            #writer.add_scalar('eval/share', share, e)\n",
    "            #writer.add_scalar('eval/diff', diff, e)\n",
    "            writer.add_graph(model_1, bidder_1.valuations) \n",
    "\n",
    "            print(\"Epoch {}: \\tutilities: \\t p1: {:.3f} \\t p2: {:.3f}\".format(e, utility_1, utility_2))\n",
    "            plot_bid_function(fig, v_1, b_1, v_2, b_2, writer,e)            \n",
    "        \n",
    "        elapsed = timer() - start_time\n",
    "        overhead_mins = overhead_mins + elapsed/60\n",
    "        writer.add_scalar('debug/overhead_mins', overhead_mins, e)\n",
    "            \n",
    "                     \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
