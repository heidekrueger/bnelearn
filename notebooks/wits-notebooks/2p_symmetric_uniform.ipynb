{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# n Player FPSB Auction with uniform symmetric valuation distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, time, warnings\n",
    "root_path = os.path.abspath(os.path.join('..'))\n",
    "if root_path not in sys.path:\n",
    "    sys.path.append(root_path)\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils as ut\n",
    "from torch.optim.optimizer import Optimizer, required\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from bnelearn.strategy import NeuralNetStrategy, ClosureStrategy\n",
    "from bnelearn.bidder import Bidder\n",
    "from bnelearn.mechanism import FirstPriceSealedBidAuction, VickreyAuction\n",
    "from bnelearn.optimizer import ES\n",
    "from bnelearn.environment import AuctionEnvironment\n",
    "\n",
    "# set up matplotlib\n",
    "is_ipython = 'inline' in plt.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "plt.rcParams['figure.figsize'] = [8, 5]\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "device = 'cuda' if cuda else 'cpu'\n",
    "\n",
    "# Use specific cuda gpu if desired (i.e. for running multiple experiments in parallel)\n",
    "specific_gpu = 3\n",
    "if cuda and specific_gpu:\n",
    "    torch.cuda.set_device(specific_gpu)\n",
    "\n",
    "print(device)\n",
    "if cuda: print(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings\n",
    "\n",
    "The following cell fully defines an experiment.\n",
    "The following set of parameters works well:\n",
    "```\n",
    "2p:  batch_size = 2**18, size_hidden_layer = 10, learning_rate = 3e-1m lr_decay = True, lr_decay_every = 500, lr_decay_factor = 0.8, momentum = 0.7, sigma = .02, n_perturbations = 128\n",
    "\n",
    "\n",
    "10p: (run 2019-07-08 Mon 01:00 with following settings was\n",
    "      NOT aggressive enough. Needs higher lr:)\n",
    "         batch_size = 2**17, size_hidden_layer = 10, learning_rate = 3e-1, lr_decay_every = 500, \n",
    "         lr_decay_factor = 0.75, momentum = 076, sigma = .02, n_perturbations = 256,\n",
    "         eval_batch_size 2**24\n",
    "         (1 hidden layer, tanh)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log in notebook folder\n",
    "# alternative for shared access to experiments:\n",
    "log_root = os.path.abspath('/srv/bnelearn/wits-experiments')\n",
    "#log_root = os.path.abspath('.')\n",
    "run_comment = '' # used in log title in addition to datetime\n",
    "save_figure_data_to_disc = True\n",
    "\n",
    "## Experiment setup\n",
    "n_players = 2\n",
    "n_items = 1\n",
    "\n",
    "# valuation distribution\n",
    "u_lo =0\n",
    "u_hi =10\n",
    "\n",
    "risk = 1 # risk parameter for agent <-- not implemented in bidder yet but used in calculation of optimal utility\n",
    "\n",
    "## Environment settings\n",
    "#training batch size\n",
    "batch_size = 2**17\n",
    "eval_batch_size = 2**25\n",
    "\n",
    "# strategy model architecture\n",
    "input_length = 1\n",
    "hidden_nodes = [5, 5]\n",
    "hidden_activations = [nn.SELU(), nn.SELU()]\n",
    "\n",
    "# optimization params\n",
    "epoch = 2000\n",
    "learning_rate = 3e-1\n",
    "lr_decay = True\n",
    "lr_decay_every = 500\n",
    "lr_decay_factor = 0.7\n",
    "momentum = 0.7\n",
    "\n",
    "sigma = .02 #ES noise parameter\n",
    "n_perturbations = 128\n",
    "\n",
    "# plot and log training options\n",
    "plot_epoch = 500\n",
    "plot_points = min(100, batch_size)\n",
    "\n",
    "plot_xmin = u_lo\n",
    "plot_xmax = u_hi\n",
    "plot_ymin = 0\n",
    "plot_ymax = 10\n",
    "\n",
    "\n",
    "def strat_to_bidder(strategy, batch_size=batch_size, player_position=None, cache_actions=False):\n",
    "    return Bidder.uniform(u_lo, u_hi, strategy,\n",
    "                          batch_size = batch_size,\n",
    "                          player_position=player_position,\n",
    "                          cache_actions=cache_actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mechanism = FirstPriceSealedBidAuction(cuda = True)\n",
    "\n",
    "model = NeuralNetStrategy(input_length,\n",
    "                          hidden_nodes = hidden_nodes,\n",
    "                          hidden_activations = hidden_activations,\n",
    "                          requires_grad=False,\n",
    "                          ensure_positive_output = torch.tensor([float(u_hi)])\n",
    "                          ).to(device)\n",
    "\n",
    "bidders = [ strat_to_bidder(model, batch_size, player_position)\n",
    "           for player_position in range(n_players)]\n",
    "\n",
    "env = AuctionEnvironment(mechanism,\n",
    "                  agents = bidders,\n",
    "                  batch_size = batch_size,\n",
    "                  n_players =n_players,\n",
    "                  strategy_to_player_closure = strat_to_bidder\n",
    "                 )\n",
    "optimizer = ES(model=model, environment = env,\n",
    "               lr = learning_rate, momentum=momentum,\n",
    "               sigma=sigma, n_perturbations=n_perturbations)\n",
    "\n",
    "print(model)\n",
    "n_parameters = sum([p.numel() for p in model.parameters()])\n",
    "print('Total parameters: ' + str(n_parameters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up Evaluation and logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the symmetric $\\sim U (\\ \\underline v, \\overline v \\ )$ setting with risk parameter $r$ and $n$ players, the bne-optimal bid is given by (Cox et al 1982)\n",
    "\n",
    "$$b^*(v) = \\underline v + \\frac{n - 1}{n-1+r} (v - \\underline v) $$\n",
    "\n",
    "The expected utility in the bne can then be calculated using\n",
    "\n",
    "$$E[u_{BNE}] = \\int_{\\underline v}^{\\overline v}{P(win | b) * u(b,v | win) *pdf(v) dv}$$\n",
    "\n",
    "In this setting, we have:\n",
    "\n",
    "$P(win | b) = P(b_i > b_j, \\forall j\\neq i) = P(b_i > b_j)^{n-1} = {\\frac{v - \\underline v}{\\overline v - \\underline v}}^{n-1}$,\n",
    "\n",
    "$u(b,v | win) = v - b^*(v) = \\frac{r}{n-1+r}$, where we use monotonicity and symmetry (i.e. $v_i \\geq v_j \\iff b_i \\geq b_j$\n",
    "\n",
    "$pdf(v) = \\frac{1}{\\overline v - \\underline v} $\n",
    "\n",
    "The integral above then works out to\n",
    "$$E(u_{BNE}) = \\frac{r(\\overline v - \\underline v)}{(n-1+r)(n+1)}  $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for evaluation\n",
    "def optimal_bid(valuation):\n",
    "    return valuation * (n_players - 1) / n_players\n",
    "\n",
    "#calculate analytical bne_utility\n",
    "bne_utility = risk/(n_players - 1 + risk)*(u_hi - u_lo)/(n_players+1)\n",
    "\n",
    "bneStrategy = ClosureStrategy(optimal_bid)\n",
    "\n",
    "# environment filled with optimal players for logging\n",
    "# use higher batch size for calculating optimum\n",
    "bne_env = AuctionEnvironment(mechanism,\n",
    "                            agents = [strat_to_bidder(bneStrategy,\n",
    "                                                      player_position= i,\n",
    "                                                      batch_size = eval_batch_size,\n",
    "                                                      cache_actions=True)\n",
    "                                      for i in range(n_players)\n",
    "                                     ],\n",
    "                            batch_size = eval_batch_size,\n",
    "                            n_players=n_players,\n",
    "                            strategy_to_player_closure = strat_to_bidder\n",
    "                           )\n",
    "\n",
    "# when calculating utilities, make sure valuations are drawn at least once.\n",
    "print(\"Utility in BNE (analytical): \\t{:.5f}\".format(bne_utility))\n",
    "bne_utility_sampled = bne_env.get_reward(bne_env.agents[0], draw_valuations=True)\n",
    "print('Utility in BNE (sampled): \\t{:.5f}'.format(bne_utility_sampled))\n",
    "utility_vs_bne = bne_env.get_strategy_reward(model, player_position=0)\n",
    "print('Model utility vs BNE: \\t\\t{:.5f}'.format(utility_vs_bne))\n",
    "utility_learning_env = env.get_strategy_reward(model, player_position=0, draw_valuations = True)\n",
    "print('Model utility in learning env:\\t{:.5f}'.format(utility_learning_env))\n",
    "\n",
    "v_opt = np.linspace(plot_xmin, plot_xmax, 100)\n",
    "b_opt = optimal_bid(v_opt)\n",
    "    \n",
    "def plot_bid_function(fig, v,b, writer=None, e=None, plot_points=plot_points,\n",
    "                      save_vectors_to_disc=save_figure_data_to_disc):\n",
    "    \n",
    "    # subsample points and plot\n",
    "    v = v.detach().cpu().numpy()[:plot_points]\n",
    "    b= b.detach().cpu().numpy()[:plot_points]\n",
    "    \n",
    "    if save_vectors_to_disc:\n",
    "        np.savez(\n",
    "            os.path.join(logdir, 'figure_data.npz'),\n",
    "            v_opt = v_opt,\n",
    "            b_opt = b_opt,\n",
    "            v = v, b = b\n",
    "        )\n",
    "    \n",
    "    \n",
    "    fig = plt.gcf()\n",
    "    plt.cla()\n",
    "    plt.xlim(plot_xmin, plot_xmax)\n",
    "    plt.ylim(plot_ymin, plot_ymax)\n",
    "    plt.plot(v,b, 'o', v_opt, b_opt, 'r--')\n",
    "    #if is_ipython:\n",
    "        #display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())\n",
    "    if writer:\n",
    "        writer.add_figure('eval/bid_function', fig, e)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_once(writer, e):\n",
    "    \"\"\"Everything that should be logged only once on initialization.\"\"\"\n",
    "    writer.add_scalar('debug/total_model_parameters', n_parameters, e)\n",
    "    writer.add_text('hyperparams/neural_net_spec', str(model), 0)    \n",
    "    writer.add_scalar('debug/eval_batch_size', eval_batch_size, e)\n",
    "    writer.add_graph(model, env.agents[0].valuations)    \n",
    "    \n",
    "def log_metrics(writer, e):\n",
    "    writer.add_scalar('eval/utility', utility, e)\n",
    "    writer.add_scalar('debug/norm_parameter_update', update_norm, e)\n",
    "    writer.add_scalar('eval/utility_vs_bne', utility_vs_bne, e)\n",
    "    writer.add_scalar('eval/epsilon_relative', epsilon_relative, e)\n",
    "    writer.add_scalar('debug/epsilon_absolute', epsilon_absolute, e) # debug because only interesting to see if numeric precision is a problem, otherwise same as relative but scaled.\n",
    "\n",
    "\n",
    "\n",
    "def log_hyperparams(writer, e):\n",
    "    \"\"\"Everything that should be logged on every learning_rate updates\"\"\"\n",
    "    writer.add_scalar('hyperparams/batch_size', batch_size, e)\n",
    "    writer.add_scalar('hyperparams/learning_rate', learning_rate, e)\n",
    "    writer.add_scalar('hyperparams/momentum', momentum, e)\n",
    "    writer.add_scalar('hyperparams/sigma', sigma, e)\n",
    "    writer.add_scalar('hyperparams/n_perturbations', n_perturbations, e)\n",
    "\n",
    "def training_loop(e, writer):    \n",
    "    global overhead_mins, learning_rate,\\\n",
    "        utility, utility_vs_bne, epsilon_relative, epsilon_absolute, update_norm\n",
    "    \n",
    "    if lr_decay and e % lr_decay_every == 0 and e > 0:\n",
    "        learning_rate = learning_rate * lr_decay_factor\n",
    "        log_hyperparams(writer, e)\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = learning_rate\n",
    "\n",
    "    ### do in every iteration ###\n",
    "    # save current params to calculate update norm\n",
    "    prev_params = torch.nn.utils.parameters_to_vector(model.parameters())\n",
    "    #update model\n",
    "    utility = -optimizer.step()\n",
    "    \n",
    "    ## everything after this is logging --> measure overhead\n",
    "    start_time = timer()\n",
    "    \n",
    "    # calculate infinity-norm of update step\n",
    "    new_params = torch.nn.utils.parameters_to_vector(model.parameters())\n",
    "    update_norm = (new_params - prev_params).norm(float('inf'))    \n",
    "    # calculate utility vs bne    \n",
    "    utility_vs_bne = bne_env.get_reward(strat_to_bidder(model, batch_size = eval_batch_size), draw_valuations=False)\n",
    "    epsilon_relative = 1 - utility_vs_bne / bne_utility\n",
    "    epsilon_absolute = bne_utility - utility_vs_bne\n",
    "    \n",
    "    log_metrics(writer, e)\n",
    "    \n",
    "    if e % plot_epoch == 0:\n",
    "        # plot current function output\n",
    "        #bidder = strat_to_bidder(model, batch_size)\n",
    "        #bidder.draw_valuations_()\n",
    "        v = bidders[0].valuations\n",
    "        b = bidders[0].get_action()\n",
    "\n",
    "        print(\"Epoch {}: \\tcurrent utility: {:.3f},\\t utility vs BNE: {:.3f}, \\tepsilon (abs/rel): ({:.5f}, {:.5f})\".format(e, utility, utility_vs_bne, epsilon_absolute, epsilon_relative))\n",
    "        plot_bid_function(fig, v,b,writer,e)\n",
    "            \n",
    "    elapsed = timer() - start_time        \n",
    "    overhead_mins = overhead_mins + elapsed/60\n",
    "    writer.add_scalar('debug/overhead_mins', overhead_mins, e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup logger\n",
    "if os.name == 'nt': raise ValueError('The run_name may not contain : on Windows! (change datetime format to fix this)') \n",
    "run_name = time.strftime('%Y-%m-%d %a %H:%M')\n",
    "if run_comment:\n",
    "    run_name = run_name + ' - ' + str(run_comment)\n",
    "logdir = os.path.join(log_root, 'fpsb', 'symmetric', 'uniform', str(n_players) + 'p', run_name)\n",
    "\n",
    "e = 0\n",
    "overhead_mins = 0\n",
    "\n",
    "print(logdir)\n",
    "fig = plt.figure()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "with SummaryWriter(logdir, flush_secs=60) as writer:\n",
    "    \n",
    "    torch.cuda.empty_cache()    \n",
    "    log_once(writer, 0)\n",
    "    log_hyperparams(writer, 0)    \n",
    "    \n",
    "    for e in range(e,e+epoch+1):\n",
    "        training_loop(e, writer)       \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
