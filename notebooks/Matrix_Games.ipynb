{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playing Simple Games with Neural Nets\n",
    "\n",
    "In this notebook, we implement equilibria learning viea self play for simple games such as Battle of the Sexes and Matching Pennies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "root_path = os.path.abspath(os.path.join('..'))\n",
    "if root_path not in sys.path:\n",
    "    sys.path.append(root_path)\n",
    "    \n",
    "import torch\n",
    "from bnelearn.strategy import MatrixGameStrategy\n",
    "from bnelearn.bidder import Bidder, Player, MatrixGamePlayer\n",
    "from bnelearn.mechanism import PrisonersDilemma, BattleOfTheSexes, MatchingPennies\n",
    "from bnelearn.optimizer import ES\n",
    "from bnelearn.environment import Environment, AuctionEnvironment, MatrixGameEnvironment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Symmetric Game: Prisoners' Dilemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 5\n",
    "logdir = os.path.join(root_path, 'notebooks', 'pd', str(experiment_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Experiment setup\n",
    "n_players = 2\n",
    "\n",
    "## Environment settings\n",
    "#training batch size\n",
    "batch_size = 64\n",
    "input_length = 1\n",
    "\n",
    "\n",
    "# optimization params\n",
    "epoch = 25\n",
    "learning_rate = 1\n",
    "lr_decay = False\n",
    "lr_decay_every = 1000\n",
    "lr_decay_factor = 0.8\n",
    "\n",
    "sigma = 5 #ES noise parameter\n",
    "n_perturbations = 8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapper transforming a strategy to bidder, used by the optimizer\n",
    "# this is a dummy, valuation doesn't matter\n",
    "def strat_to_player(strategy, batch_size, player_position=None):\n",
    "    return MatrixGamePlayer(strategy, batch_size = batch_size, player_position=player_position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MatrixGameStrategy(n_actions=2).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game = PrisonersDilemma()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = AuctionEnvironment(game, \n",
    "                 agents=[],\n",
    "                 max_env_size =1,\n",
    "                 n_players=2,\n",
    "                 batch_size=batch_size,\n",
    "                 strategy_to_bidder_closure=strat_to_player)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = ES(model=model, environment = env, lr = learning_rate, sigma=sigma, n_perturbations=n_perturbations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_hyperparams(writer):\n",
    "    writer.add_scalar('hyperparams/batch_size', batch_size)\n",
    "    writer.add_scalar('hyperparams/learning_rate', learning_rate)\n",
    "    writer.add_scalar('hyperparams/sigma', sigma)\n",
    "    writer.add_scalar('hyperparams/n_perturbations', n_perturbations)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with SummaryWriter(log_dir=logdir, flush_secs=30) as writer:\n",
    "    torch.cuda.empty_cache()\n",
    "    log_hyperparams(writer)\n",
    "\n",
    "    for e in range(epoch+1):    \n",
    "\n",
    "        # lr decay?\n",
    "        if lr_decay and e % lr_decay_every == 0 and e > 0:\n",
    "            learning_rate = learning_rate * lr_decay_factor\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = learning_rate\n",
    "            writer.add_scalar('hyperparams/learning_rate', learning_rate, e)\n",
    "\n",
    "        # always: do optimizer step\n",
    "        utility = -optimizer.step()\n",
    "        writer.add_scalar('eval/utility', utility, e) \n",
    "        writer.add_scalar('eval/prob_action_0', model.distribution.probs[0], e)    \n",
    "        #print(list(model.named_parameters()))\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player = strat_to_player(model, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player.get_action().float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assymmetric Games, BoS and Matching Pennies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Experiment setup\n",
    "n_players = 2\n",
    "\n",
    "## Environment settings\n",
    "#training batch size\n",
    "batch_size = 2**5\n",
    "input_length = 1\n",
    "\n",
    "\n",
    "# optimization params\n",
    "epoch = 200\n",
    "learning_rate = 1\n",
    "lr_decay = False\n",
    "lr_decay_every = 100\n",
    "lr_decay_factor = 0.8\n",
    "\n",
    "sigma = 5 #ES noise parameter\n",
    "n_perturbations = 10\n",
    "\n",
    "game = MatchingPennies()\n",
    "directory_name = 'matching_pennies'\n",
    "experiment_name = '04-01-batch=32'\n",
    "logdir = os.path.join(root_path, 'notebooks', directory_name, str(experiment_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapper transforming a strategy to bidder, used by the optimizer\n",
    "# this is a dummy, valuation doesn't matter\n",
    "def strat_to_player(strategy, batch_size, player_position=None):\n",
    "    return MatrixGamePlayer(strategy, batch_size = batch_size,  player_position=player_position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = MatrixGameStrategy(n_actions=2).cuda()\n",
    "model2 = MatrixGameStrategy(n_actions=2).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = MatrixGameEnvironment(game, agents=[model1, model2],\n",
    "                 n_players=2,\n",
    "                 batch_size=batch_size,\n",
    "                 strategy_to_player_closure=strat_to_player,\n",
    "                 env_type = 'fixed'\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer1 = ES(model=model1, environment = env, lr = learning_rate, sigma=sigma, n_perturbations=n_perturbations, env_type='fixed', strat_to_bidder_kwargs={'player_position':0})\n",
    "optimizer2 = ES(model=model2, environment = env, lr = learning_rate, sigma=sigma, n_perturbations=n_perturbations, env_type='fixed', strat_to_bidder_kwargs={'player_position':1})\n",
    "optimizers = [optimizer1, optimizer2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_hyperparams(writer):\n",
    "    writer.add_scalar('hyperparams/batch_size', batch_size)\n",
    "    writer.add_scalar('hyperparams/learning_rate', learning_rate)\n",
    "    writer.add_scalar('hyperparams/sigma', sigma)\n",
    "    writer.add_scalar('hyperparams/n_perturbations', n_perturbations)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.distribution.probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.distribution.probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with SummaryWriter(log_dir=logdir) as writer:\n",
    "    torch.cuda.empty_cache()\n",
    "    log_hyperparams(writer)\n",
    "\n",
    "    for e in range(epoch+1):    \n",
    "\n",
    "        # lr decay?\n",
    "        if lr_decay and e % lr_decay_every == 0 and e > 0:\n",
    "            learning_rate = learning_rate * lr_decay_factor\n",
    "            writer.add_scalar('hyperparams/learning_rate', learning_rate, e)\n",
    "            for optimizer in optimizers:\n",
    "                for param_group in optimizer.param_groups:\n",
    "                    param_group['lr'] = learning_rate\n",
    "\n",
    "\n",
    "        # always: do optimizer step\n",
    "        utility1 = -optimizer1.step()\n",
    "        writer.add_scalar('eval/p1_utility', utility1, e) \n",
    "        writer.add_scalar('eval/p1_prob_action_0', model1.distribution.probs[0], e)\n",
    "\n",
    "        utility2 =  -optimizer2.step()\n",
    "        writer.add_scalar('eval/p2_utility', utility2, e)\n",
    "        writer.add_scalar('eval/p2_prob_action_0', model2.distribution.probs[0], e)\n",
    "        #print(list(model.named_parameters()))\n",
    "        if not e % 50: print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utility1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utility2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
