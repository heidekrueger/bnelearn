{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playing Simple Games with Neural Nets\n",
    "\n",
    "In this notebook, we implement equilibria learning viea self play for simple games such as Battle of the Sexes and Matching Pennies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "root_path = os.path.abspath(os.path.join('..'))\n",
    "if root_path not in sys.path:\n",
    "    sys.path.append(root_path)\n",
    "    \n",
    "import torch\n",
    "from bnelearn.strategy import MatrixGameStrategy\n",
    "from bnelearn.bidder import Bidder\n",
    "from bnelearn.mechanism import TwoByTwoBimatrixGame\n",
    "from bnelearn.optimizer import ES\n",
    "from bnelearn.environment import Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Experiment setup\n",
    "n_players = 2\n",
    "\n",
    "## Environment settings\n",
    "#training batch size\n",
    "batch_size = 2**10\n",
    "input_length = 1\n",
    "\n",
    "\n",
    "# optimization params\n",
    "epoch = 100\n",
    "learning_rate = 1\n",
    "lr_decay = False\n",
    "lr_decay_every = 1000\n",
    "lr_decay_factor = 0.8\n",
    "\n",
    "sigma = 5 #ES noise parameter\n",
    "n_perturbations = 8\n",
    "\n",
    "name = 13\n",
    "namestr = './pb/{}'.format(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prisoners dilemma\n",
    "pd = torch.tensor([[[-1, -1],[-3, 0]], [[ 0, -3],[-2,-2]]])\n",
    "prisoners_dilemma = TwoByTwoBimatrixGame(pd)\n",
    "\n",
    "# battle of sexes. ! won't work, game is noy symmetric!\n",
    "mp = torch.tensor([[[3, 2],[0,0]], [[0,0],[2,3]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapper transforming a strategy to bidder, used by the optimizer\n",
    "# this is a dummy, valuation doesn't matter\n",
    "def strat_to_bidder(strategy, batch_size):\n",
    "    return Bidder.uniform(0,0, strategy, batch_size = batch_size, n_players=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MatrixGameStrategy(n_actions=2).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "game = prisoners_dilemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Environment(game, environment_agents=[],\n",
    "                 max_env_size =1,\n",
    "                 n_players=2,\n",
    "                 batch_size=batch_size,\n",
    "                 strategy_to_bidder_closure=strat_to_bidder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = ES(model=model, environment = env, lr = learning_rate, sigma=sigma, n_perturbations=n_perturbations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_hyperparams(writer):\n",
    "    writer.add_scalar('hyperparams/batch_size', batch_size)\n",
    "    writer.add_scalar('hyperparams/learning_rate', learning_rate)\n",
    "    writer.add_scalar('hyperparams/sigma', sigma)\n",
    "    writer.add_scalar('hyperparams/n_perturbations', n_perturbations)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "writer = SummaryWriter(log_dir=namestr)\n",
    "log_hyperparams(writer)\n",
    "\n",
    "for e in range(epoch+1):    \n",
    "    \n",
    "    # lr decay?\n",
    "    if lr_decay and e % lr_decay_every == 0 and e > 0:\n",
    "        learning_rate = learning_rate * lr_decay_factor\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = learning_rate\n",
    "        writer.add_scalar('hyperparams/learning_rate', learning_rate, e)\n",
    "        \n",
    "    # always: do optimizer step\n",
    "    utility = -optimizer.step()\n",
    "    writer.add_scalar('eval/utility', utility, e) \n",
    "    writer.add_scalar('eval/prob_action_0', model.distribution.probs[0], e)    \n",
    "    #print(list(model.named_parameters()))\n",
    "    print(e)\n",
    "        \n",
    "torch.cuda.empty_cache()\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
