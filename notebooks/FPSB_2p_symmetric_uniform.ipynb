{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Player FPSB Auction with symmetric unfirorm valuation distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "root_path = os.path.abspath(os.path.join('..'))\n",
    "if root_path not in sys.path:\n",
    "    sys.path.append(root_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils as ut\n",
    "from torch.optim.optimizer import Optimizer, required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bnelearn.strategy import NeuralNetStrategy, TruthfulStrategy\n",
    "from bnelearn.bidder import Bidder\n",
    "from bnelearn.mechanism import FirstPriceSealedBidAuction, VickreyAuction\n",
    "from bnelearn.optimizer import ES\n",
    "from bnelearn.environment import AuctionEnvironment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = torch.cuda.is_available()\n",
    "device = 'cuda' if cuda else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_dir = 'fpsb'\n",
    "run_name = 'momentum'\n",
    "logdir = os.path.join(root_path, 'notebooks', run_dir , run_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Experiment setup\n",
    "n_players = 2\n",
    "n_items = 1\n",
    "# valuation distribution\n",
    "u_lo =0\n",
    "u_hi =10\n",
    "\n",
    "## Environment settings\n",
    "#training batch size\n",
    "batch_size = 2**5\n",
    "input_length = 1\n",
    "\n",
    "# model architecture\n",
    "size_hidden_layer = 20\n",
    "\n",
    "# optimization params\n",
    "epoch = 10000\n",
    "learning_rate = 2e-2\n",
    "lr_decay = True\n",
    "lr_decay_every = 2000\n",
    "lr_decay_factor = 0.8\n",
    "momentum = 0.8\n",
    "\n",
    "sigma = .1 #ES noise parameter\n",
    "n_perturbations = 32\n",
    "\n",
    "# plot and log training options\n",
    "plot_epoch = 50\n",
    "plot_points = min(150, batch_size)\n",
    "sample_points = torch.from_numpy(np.linspace(u_lo, u_hi, u_hi+1)).float().view(-1, n_items).cuda()\n",
    "\n",
    "# tensorboard writer settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for evaluation\n",
    "def optimal_bid(valuation):\n",
    "    return valuation / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapper transforming a strategy to bidder, used by the optimizer\n",
    "def strat_to_bidder(strategy, batch_size):\n",
    "    return Bidder.uniform(u_lo,u_hi, strategy, batch_size = batch_size, n_players=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetStrategy(input_length,\n",
    "                          size_hidden_layer = size_hidden_layer,\n",
    "                          requires_grad=False\n",
    "                         ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that model is on GPU if available\n",
    "next(model.parameters()).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mechanism = FirstPriceSealedBidAuction(cuda = True)\n",
    "env = AuctionEnvironment(mechanism,\n",
    "                  agents = [], #dynamically built\n",
    "                  max_env_size = 1, #\n",
    "                  batch_size = batch_size,\n",
    "                  n_players =2,\n",
    "                  strategy_to_bidder_closure = strat_to_bidder\n",
    "                 )\n",
    "optimizer = ES(model=model, environment = env,\n",
    "               lr = learning_rate, sigma=sigma, n_perturbations=n_perturbations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_hyperparams(writer):\n",
    "    writer.add_scalar('hyperparams/batch_size', batch_size)\n",
    "    writer.add_scalar('hyperparams/size_hidden_layer', size_hidden_layer)\n",
    "    writer.add_scalar('hyperparams/learning_rate', learning_rate)\n",
    "    writer.add_scalar('hyperparams/sigma', sigma)\n",
    "    writer.add_scalar('hyperparams/n_perturbations', n_perturbations)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "writer = SummaryWriter(logdir)\n",
    "log_hyperparams(writer)\n",
    "\n",
    "for e in range(epoch+1):    \n",
    "    \n",
    "    # lr decay?\n",
    "    if lr_decay and e % lr_decay_every == 0 and e > 0:\n",
    "        learning_rate = learning_rate * lr_decay_factor\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = learning_rate\n",
    "        writer.add_scalar('hyperparams/learning_rate', learning_rate, e)\n",
    "        \n",
    "    # always: do optimizer step\n",
    "    utility = -optimizer.step()\n",
    "    writer.add_scalar('eval/utility', utility, e) \n",
    "    \n",
    "    # plot + eval\n",
    "    if e % plot_epoch == 0:\n",
    "        # plot current function output\n",
    "        bidder = strat_to_bidder(model, batch_size)\n",
    "        bidder.draw_valuations_()\n",
    "        v = bidder.valuations\n",
    "        b = bidder.get_action()\n",
    "        share = (b/v).mean()\n",
    "        writer.add_scalar('eval/utility', utility, e)\n",
    "        writer.add_scalar('eval/share', share, e)       \n",
    "            \n",
    "        print(\"Epoch {}: \\tavg bid: {:2f}, \\tutility: {:2f}\".format(e, share, utility))                \n",
    "        \n",
    "        # subsample points and plot\n",
    "        v = v.detach().cpu().numpy()[:plot_points]\n",
    "        b= b.detach().cpu().numpy()[:plot_points]\n",
    "        optimal = optimal_bid(v)        \n",
    "        fig = plt.figure()\n",
    "        plt.plot(v,b, 'o', v, optimal, 'r-')        \n",
    "        writer.add_figure('eval/bid_function', fig, e)        \n",
    "        plt.show()\n",
    "        \n",
    "        # first step: write model\n",
    "        if e==0:\n",
    "            writer.add_graph(model, bidder.valuations)        \n",
    "    \n",
    "   \n",
    "        \n",
    "torch.cuda.empty_cache()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
