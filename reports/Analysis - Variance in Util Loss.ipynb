{
 "cells": [
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis: Variance in util loss\n",
    "\n",
    "Date: 15.07.2020 Author: Stefan Heidekrüger\n",
    "\n",
    "## TL:DR\n",
    "\n",
    "When evaluating the ex-ante ('exa') and maximum ex-interim ('mexi') utility loss in the analytical bne, there is still some aleatoric uncertainty only coming from the different valuations.\n",
    "For some of our settings, this variance is so high that EVEN THE ANALYTICAL BNE would not be deemed 'static' / 'converged' under our current stopping criterion with current parameters.\n",
    "\n",
    "Below we consider the two settings of Uniform 10p Risk Averse and the overlapping uniform asymmetric case. In the former, calculating the exa-loss for the true bne yields a mean of 0.0001 with a std of 1.2e-5, which would still fulfill the stopping criterion.\n",
    "\n",
    "However, in the latter, we get the following:\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "Thus, even the TRUE bne would not fulfill the stopping criterion (neither at 0.0001 nor 0.0005) in this setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import sys\n",
    "root_path = os.path.join(os.path.expanduser('~'), 'bnelearn')\n",
    "if root_path not in sys.path:\n",
    "    sys.path.append(root_path)\n",
    "    \n",
    "import torch\n",
    "    \n",
    "import bnelearn\n",
    "from bnelearn.experiment.configuration_manager import ConfigurationManager\n",
    "import bnelearn.util.metrics as metrics\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_gpu = 6\n",
    "torch.cuda.set_device(specific_gpu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uniform Symmetric 10p Risk Averse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utility in BNE (sampled): \t0.02187\n",
      "Utility in BNE (analytic): \t0.02185\n",
      "Using analytical BNE utility.\n"
     ]
    }
   ],
   "source": [
    "payment_rule = 'first_price'\n",
    "risk = 0.5\n",
    "n_players = [2,3,5,10]\n",
    "\n",
    "# Learning\n",
    "batch_size = 2 ** 18\n",
    "\n",
    "util_loss_batch_size = 2 ** 12\n",
    "util_loss_grid_size = 2 ** 13\n",
    "log_metrics = {'opt': True,#True\n",
    "               'l2': True,#True\n",
    "               'util_loss': True}\n",
    "experiment_type = 'single_item_uniform_symmetric'\n",
    "log_root_dir = os.path.join(os.path.expanduser('~'), 'bnelearn', 'experiments')\n",
    "n_players=10\n",
    "\n",
    "experiment_config, experiment_class = ConfigurationManager(experiment_type=experiment_type) \\\n",
    "    .get_config(log_root_dir=log_root_dir,\n",
    "                # Run\n",
    "                n_runs = 10,\n",
    "                n_epochs = 5000,\n",
    "                #Setting\n",
    "                payment_rule=payment_rule,\n",
    "                risk=risk,\n",
    "                n_players=n_players,\n",
    "                core_solver=\"mpc\",\n",
    "                # Learning\n",
    "                hidden_nodes = [10,10],\n",
    "                hidden_activations = [nn.SELU(),nn.SELU()],\n",
    "                learner_hyperparams = {'population_size': 64,\n",
    "                                    'sigma': 1.,\n",
    "                                    'scale_sigma_by_model_size': True},\n",
    "                optimizer_hyperparams = {'lr': 1e-3},\n",
    "                optimizer_type='adam',\n",
    "                pretrain_iters=500,\n",
    "                batch_size=batch_size,\n",
    "                model_sharing=False,\n",
    "                # Hardware\n",
    "                specific_gpu=specific_gpu,\n",
    "                # Logging\n",
    "                util_loss_batch_size=util_loss_batch_size,\n",
    "                util_loss_grid_size=util_loss_grid_size,\n",
    "                util_loss_frequency=100,\n",
    "                log_metrics=log_metrics,\n",
    "                eval_batch_size=2 ** 22,\n",
    "                enable_logging=False,\n",
    "                save_tb_events_to_csv_detailed=False,\n",
    "                save_tb_events_to_binary_detailed=False)\n",
    "\n",
    "experiment = experiment_class(experiment_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 91/4096 [00:00<00:04, 905.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed computing util_loss as batch. Trying sequential valuations computation. Decrease dimensions to fix. Error:\n",
      " CUDA out of memory. Tried to allocate 512.00 GiB (GPU 6; 10.76 GiB total capacity; 2.69 GiB already allocated; 6.52 GiB free; 3.53 GiB reserved in total by PyTorch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4096/4096 [00:31<00:00, 128.10it/s]\n",
      "  2%|▏         | 91/4096 [00:00<00:04, 905.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed computing util_loss as batch. Trying sequential valuations computation. Decrease dimensions to fix. Error:\n",
      " CUDA out of memory. Tried to allocate 512.00 GiB (GPU 6; 10.76 GiB total capacity; 2.69 GiB already allocated; 6.58 GiB free; 3.47 GiB reserved in total by PyTorch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4096/4096 [00:31<00:00, 128.11it/s]\n",
      "  2%|▏         | 91/4096 [00:00<00:04, 905.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed computing util_loss as batch. Trying sequential valuations computation. Decrease dimensions to fix. Error:\n",
      " CUDA out of memory. Tried to allocate 512.00 GiB (GPU 6; 10.76 GiB total capacity; 2.69 GiB already allocated; 6.58 GiB free; 3.47 GiB reserved in total by PyTorch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4096/4096 [00:31<00:00, 128.08it/s]\n",
      "  2%|▏         | 91/4096 [00:00<00:04, 905.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed computing util_loss as batch. Trying sequential valuations computation. Decrease dimensions to fix. Error:\n",
      " CUDA out of memory. Tried to allocate 512.00 GiB (GPU 6; 10.76 GiB total capacity; 2.69 GiB already allocated; 6.58 GiB free; 3.47 GiB reserved in total by PyTorch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4096/4096 [00:31<00:00, 128.08it/s]\n",
      "  2%|▏         | 91/4096 [00:00<00:04, 905.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed computing util_loss as batch. Trying sequential valuations computation. Decrease dimensions to fix. Error:\n",
      " CUDA out of memory. Tried to allocate 512.00 GiB (GPU 6; 10.76 GiB total capacity; 2.69 GiB already allocated; 6.58 GiB free; 3.47 GiB reserved in total by PyTorch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4096/4096 [00:31<00:00, 128.07it/s]\n",
      "  2%|▏         | 91/4096 [00:00<00:04, 905.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed computing util_loss as batch. Trying sequential valuations computation. Decrease dimensions to fix. Error:\n",
      " CUDA out of memory. Tried to allocate 512.00 GiB (GPU 6; 10.76 GiB total capacity; 2.69 GiB already allocated; 6.58 GiB free; 3.47 GiB reserved in total by PyTorch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4096/4096 [00:31<00:00, 128.08it/s]\n",
      "  2%|▏         | 91/4096 [00:00<00:04, 905.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed computing util_loss as batch. Trying sequential valuations computation. Decrease dimensions to fix. Error:\n",
      " CUDA out of memory. Tried to allocate 512.00 GiB (GPU 6; 10.76 GiB total capacity; 2.69 GiB already allocated; 6.58 GiB free; 3.47 GiB reserved in total by PyTorch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4096/4096 [00:31<00:00, 128.07it/s]\n",
      "  2%|▏         | 91/4096 [00:00<00:04, 905.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed computing util_loss as batch. Trying sequential valuations computation. Decrease dimensions to fix. Error:\n",
      " CUDA out of memory. Tried to allocate 512.00 GiB (GPU 6; 10.76 GiB total capacity; 2.69 GiB already allocated; 6.58 GiB free; 3.47 GiB reserved in total by PyTorch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4096/4096 [00:31<00:00, 128.08it/s]\n",
      "  2%|▏         | 91/4096 [00:00<00:04, 905.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed computing util_loss as batch. Trying sequential valuations computation. Decrease dimensions to fix. Error:\n",
      " CUDA out of memory. Tried to allocate 512.00 GiB (GPU 6; 10.76 GiB total capacity; 2.69 GiB already allocated; 6.58 GiB free; 3.47 GiB reserved in total by PyTorch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4096/4096 [00:31<00:00, 128.07it/s]\n",
      "  2%|▏         | 91/4096 [00:00<00:04, 905.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed computing util_loss as batch. Trying sequential valuations computation. Decrease dimensions to fix. Error:\n",
      " CUDA out of memory. Tried to allocate 512.00 GiB (GPU 6; 10.76 GiB total capacity; 2.69 GiB already allocated; 6.58 GiB free; 3.47 GiB reserved in total by PyTorch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4096/4096 [00:31<00:00, 128.08it/s]\n",
      "  2%|▏         | 91/4096 [00:00<00:04, 905.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed computing util_loss as batch. Trying sequential valuations computation. Decrease dimensions to fix. Error:\n",
      " CUDA out of memory. Tried to allocate 512.00 GiB (GPU 6; 10.76 GiB total capacity; 2.69 GiB already allocated; 6.58 GiB free; 3.47 GiB reserved in total by PyTorch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4096/4096 [00:31<00:00, 128.08it/s]\n",
      "  2%|▏         | 91/4096 [00:00<00:04, 905.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed computing util_loss as batch. Trying sequential valuations computation. Decrease dimensions to fix. Error:\n",
      " CUDA out of memory. Tried to allocate 512.00 GiB (GPU 6; 10.76 GiB total capacity; 2.69 GiB already allocated; 6.58 GiB free; 3.47 GiB reserved in total by PyTorch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4096/4096 [00:31<00:00, 128.08it/s]\n",
      "  2%|▏         | 91/4096 [00:00<00:04, 905.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed computing util_loss as batch. Trying sequential valuations computation. Decrease dimensions to fix. Error:\n",
      " CUDA out of memory. Tried to allocate 512.00 GiB (GPU 6; 10.76 GiB total capacity; 2.69 GiB already allocated; 6.58 GiB free; 3.47 GiB reserved in total by PyTorch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4096/4096 [00:31<00:00, 128.08it/s]\n",
      "  2%|▏         | 91/4096 [00:00<00:04, 905.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed computing util_loss as batch. Trying sequential valuations computation. Decrease dimensions to fix. Error:\n",
      " CUDA out of memory. Tried to allocate 512.00 GiB (GPU 6; 10.76 GiB total capacity; 2.69 GiB already allocated; 6.58 GiB free; 3.47 GiB reserved in total by PyTorch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4096/4096 [00:31<00:00, 128.08it/s]\n",
      "  2%|▏         | 91/4096 [00:00<00:04, 905.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed computing util_loss as batch. Trying sequential valuations computation. Decrease dimensions to fix. Error:\n",
      " CUDA out of memory. Tried to allocate 512.00 GiB (GPU 6; 10.76 GiB total capacity; 2.69 GiB already allocated; 6.58 GiB free; 3.47 GiB reserved in total by PyTorch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4096/4096 [00:31<00:00, 128.07it/s]\n",
      "  2%|▏         | 91/4096 [00:00<00:04, 905.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed computing util_loss as batch. Trying sequential valuations computation. Decrease dimensions to fix. Error:\n",
      " CUDA out of memory. Tried to allocate 512.00 GiB (GPU 6; 10.76 GiB total capacity; 2.69 GiB already allocated; 6.58 GiB free; 3.47 GiB reserved in total by PyTorch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4096/4096 [00:31<00:00, 128.08it/s]\n",
      "  2%|▏         | 91/4096 [00:00<00:04, 905.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed computing util_loss as batch. Trying sequential valuations computation. Decrease dimensions to fix. Error:\n",
      " CUDA out of memory. Tried to allocate 512.00 GiB (GPU 6; 10.76 GiB total capacity; 2.69 GiB already allocated; 6.58 GiB free; 3.47 GiB reserved in total by PyTorch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4096/4096 [00:31<00:00, 128.07it/s]\n",
      "  2%|▏         | 91/4096 [00:00<00:04, 905.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed computing util_loss as batch. Trying sequential valuations computation. Decrease dimensions to fix. Error:\n",
      " CUDA out of memory. Tried to allocate 512.00 GiB (GPU 6; 10.76 GiB total capacity; 2.69 GiB already allocated; 6.58 GiB free; 3.47 GiB reserved in total by PyTorch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4096/4096 [00:31<00:00, 128.08it/s]\n",
      "  2%|▏         | 91/4096 [00:00<00:04, 905.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed computing util_loss as batch. Trying sequential valuations computation. Decrease dimensions to fix. Error:\n",
      " CUDA out of memory. Tried to allocate 512.00 GiB (GPU 6; 10.76 GiB total capacity; 2.69 GiB already allocated; 6.58 GiB free; 3.47 GiB reserved in total by PyTorch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4096/4096 [00:31<00:00, 128.08it/s]\n",
      "  2%|▏         | 91/4096 [00:00<00:04, 905.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed computing util_loss as batch. Trying sequential valuations computation. Decrease dimensions to fix. Error:\n",
      " CUDA out of memory. Tried to allocate 512.00 GiB (GPU 6; 10.76 GiB total capacity; 2.69 GiB already allocated; 6.58 GiB free; 3.47 GiB reserved in total by PyTorch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4096/4096 [00:31<00:00, 128.08it/s]\n"
     ]
    }
   ],
   "source": [
    "exa_losses = []\n",
    "mexi_losses = []\n",
    "for i in range(20):\n",
    "    experiment.bne_env.prepare_iteration()\n",
    "    agent = experiment.bne_env.agents[0]\n",
    "    valuation = agent.valuations[:util_loss_batch_size, ...]\n",
    "    grid = agent.get_valuation_grid(util_loss_grid_size, True)\n",
    "    eq_bid_profile = torch.empty(util_loss_batch_size, experiment.n_players, agent.n_items)\n",
    "    for a in experiment.bne_env.agents:\n",
    "        eq_bid_profile[:, a.player_position, :] = a.get_action()[:util_loss_batch_size, ...]\n",
    "    ex_i_loss, _ = metrics.ex_interim_util_loss(\n",
    "        experiment.mechanism,eq_bid_profile, agent, valuation, grid)\n",
    "    exa_losses.append(ex_i_loss.mean().item())\n",
    "    mexi_losses.append(ex_i_loss.max().item())\n",
    "uniform_sym_risk_10_exa = torch.tensor(exa_losses)\n",
    "uniform_sym_risk_10_mexi = torch.tensor(mexi_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.00013635214418172836, 1.2634153790713754e-05)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniform_sym_risk_10_exa.mean().item(), uniform_sym_risk_10_exa.std().item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0016), tensor(0.0003))"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniform_sym_risk_10_mexi.mean(), uniform_sym_risk_10_mexi.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0002, 0.0001, 0.0001, 0.0001, 0.0001, 0.0002, 0.0001, 0.0001, 0.0001,\n",
       "        0.0002, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001,\n",
       "        0.0001, 0.0001])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniform_sym_risk_10_exa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(1.6247e-05),\n",
       " tensor(2.0427e-05),\n",
       " tensor(1.2083e-05),\n",
       " tensor(3.1553e-05),\n",
       " tensor(3.3557e-05),\n",
       " tensor(3.3557e-05),\n",
       " tensor(9.2325e-06),\n",
       " tensor(4.8988e-05),\n",
       " tensor(4.8988e-05),\n",
       " tensor(4.4220e-05),\n",
       " tensor(1.9130e-05),\n",
       " tensor(1.9130e-05),\n",
       " tensor(8.5223e-06),\n",
       " tensor(7.9643e-06),\n",
       " tensor(6.9772e-06),\n",
       " tensor(6.9772e-06),\n",
       " tensor(4.8845e-06)]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[uniform_sym_risk_10_exa[i-3:i].max()  - uniform_sym_risk_10_exa[i-3:i].min() for i in range(3,20)]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# asymm overlapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utilities in BNE1 (sampled):\t0.97034\t5.06985.\n",
      "No closed form solution for BNE utilities available in this setting. Using sampled value as baseline.\n",
      "Debug: eval_batch size:4194304\n",
      "\tReplacing sampled bne utilities by precalculated utilities with higher precision: tensor([0.9694, 5.0688])\n"
     ]
    }
   ],
   "source": [
    "experiment_type = 'single_item_asymmetric_uniform_overlapping'\n",
    "payment_rule = 'first_price'\n",
    "risk = 1.0\n",
    "n_players=2\n",
    "\n",
    "# Learning\n",
    "batch_size = 2 ** 18\n",
    "\n",
    "util_loss_batch_size = 2 ** 12\n",
    "util_loss_grid_size = 2 ** 13\n",
    "log_metrics = {'opt': True,#True\n",
    "               'l2': True,#True\n",
    "               'util_loss': True}\n",
    "\n",
    "log_root_dir = os.path.join(os.path.expanduser('~'), 'bnelearn', 'experiments')\n",
    "\n",
    "\n",
    "experiment_config, experiment_class = ConfigurationManager(experiment_type=experiment_type) \\\n",
    "    .get_config(log_root_dir=log_root_dir,\n",
    "                # Run\n",
    "                n_runs = 10,\n",
    "                n_epochs = 5000,\n",
    "                #Setting\n",
    "                payment_rule=payment_rule,\n",
    "                risk=risk,\n",
    "                n_players=n_players,\n",
    "                core_solver=\"mpc\",\n",
    "                # Learning\n",
    "                hidden_nodes = [10,10],\n",
    "                hidden_activations = [nn.SELU(),nn.SELU()],\n",
    "                learner_hyperparams = {'population_size': 64,\n",
    "                                    'sigma': 1.,\n",
    "                                    'scale_sigma_by_model_size': True},\n",
    "                optimizer_hyperparams = {'lr': 1e-3},\n",
    "                optimizer_type='adam',\n",
    "                pretrain_iters=500,\n",
    "                batch_size=batch_size,\n",
    "                model_sharing=False,\n",
    "                # Hardware\n",
    "                specific_gpu=specific_gpu,\n",
    "                # Logging\n",
    "                util_loss_batch_size=util_loss_batch_size,\n",
    "                util_loss_grid_size=util_loss_grid_size,\n",
    "                util_loss_frequency=100,\n",
    "                log_metrics=log_metrics,\n",
    "                eval_batch_size=2 ** 22,\n",
    "                enable_logging=False,\n",
    "                save_tb_events_to_csv_detailed=False,\n",
    "                save_tb_events_to_binary_detailed=False)\n",
    "\n",
    "experiment = experiment_class(experiment_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 182/4096 [00:00<00:02, 1778.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed computing util_loss as batch. Trying sequential valuations computation. Decrease dimensions to fix. Error:\n",
      " CUDA out of memory. Tried to allocate 512.00 GiB (GPU 6; 10.76 GiB total capacity; 1.47 GiB already allocated; 8.11 GiB free; 1.94 GiB reserved in total by PyTorch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4096/4096 [00:10<00:00, 391.70it/s]\n",
      "  4%|▍         | 184/4096 [00:00<00:02, 1826.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed computing util_loss as batch. Trying sequential valuations computation. Decrease dimensions to fix. Error:\n",
      " CUDA out of memory. Tried to allocate 512.00 GiB (GPU 6; 10.76 GiB total capacity; 1.47 GiB already allocated; 8.11 GiB free; 1.94 GiB reserved in total by PyTorch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4096/4096 [00:10<00:00, 391.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 184/4096 [00:00<00:02, 1821.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed computing util_loss as batch. Trying sequential valuations computation. Decrease dimensions to fix. Error:\n",
      " CUDA out of memory. Tried to allocate 512.00 GiB (GPU 6; 10.76 GiB total capacity; 1.47 GiB already allocated; 8.11 GiB free; 1.94 GiB reserved in total by PyTorch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4096/4096 [00:10<00:00, 391.69it/s]\n",
      "  4%|▍         | 184/4096 [00:00<00:02, 1825.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed computing util_loss as batch. Trying sequential valuations computation. Decrease dimensions to fix. Error:\n",
      " CUDA out of memory. Tried to allocate 512.00 GiB (GPU 6; 10.76 GiB total capacity; 1.47 GiB already allocated; 8.11 GiB free; 1.94 GiB reserved in total by PyTorch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4096/4096 [00:10<00:00, 391.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 184/4096 [00:00<00:02, 1821.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed computing util_loss as batch. Trying sequential valuations computation. Decrease dimensions to fix. Error:\n",
      " CUDA out of memory. Tried to allocate 512.00 GiB (GPU 6; 10.76 GiB total capacity; 1.47 GiB already allocated; 8.11 GiB free; 1.94 GiB reserved in total by PyTorch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4096/4096 [00:10<00:00, 391.43it/s]\n",
      "  4%|▍         | 184/4096 [00:00<00:02, 1823.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed computing util_loss as batch. Trying sequential valuations computation. Decrease dimensions to fix. Error:\n",
      " CUDA out of memory. Tried to allocate 512.00 GiB (GPU 6; 10.76 GiB total capacity; 1.47 GiB already allocated; 8.11 GiB free; 1.94 GiB reserved in total by PyTorch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4096/4096 [00:10<00:00, 390.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 184/4096 [00:00<00:02, 1824.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed computing util_loss as batch. Trying sequential valuations computation. Decrease dimensions to fix. Error:\n",
      " CUDA out of memory. Tried to allocate 512.00 GiB (GPU 6; 10.76 GiB total capacity; 1.47 GiB already allocated; 8.11 GiB free; 1.94 GiB reserved in total by PyTorch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4096/4096 [00:10<00:00, 391.14it/s]\n",
      "  4%|▍         | 184/4096 [00:00<00:02, 1822.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed computing util_loss as batch. Trying sequential valuations computation. Decrease dimensions to fix. Error:\n",
      " CUDA out of memory. Tried to allocate 512.00 GiB (GPU 6; 10.76 GiB total capacity; 1.47 GiB already allocated; 8.11 GiB free; 1.94 GiB reserved in total by PyTorch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4096/4096 [00:10<00:00, 390.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 184/4096 [00:00<00:02, 1823.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed computing util_loss as batch. Trying sequential valuations computation. Decrease dimensions to fix. Error:\n",
      " CUDA out of memory. Tried to allocate 512.00 GiB (GPU 6; 10.76 GiB total capacity; 1.47 GiB already allocated; 8.11 GiB free; 1.94 GiB reserved in total by PyTorch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4096/4096 [00:10<00:00, 391.03it/s]\n",
      "  4%|▍         | 184/4096 [00:00<00:02, 1821.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed computing util_loss as batch. Trying sequential valuations computation. Decrease dimensions to fix. Error:\n",
      " CUDA out of memory. Tried to allocate 512.00 GiB (GPU 6; 10.76 GiB total capacity; 1.47 GiB already allocated; 8.11 GiB free; 1.94 GiB reserved in total by PyTorch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4096/4096 [00:10<00:00, 390.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 184/4096 [00:00<00:02, 1823.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed computing util_loss as batch. Trying sequential valuations computation. Decrease dimensions to fix. Error:\n",
      " CUDA out of memory. Tried to allocate 512.00 GiB (GPU 6; 10.76 GiB total capacity; 1.47 GiB already allocated; 8.11 GiB free; 1.94 GiB reserved in total by PyTorch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4096/4096 [00:10<00:00, 390.99it/s]\n",
      "  4%|▍         | 184/4096 [00:00<00:02, 1822.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed computing util_loss as batch. Trying sequential valuations computation. Decrease dimensions to fix. Error:\n",
      " CUDA out of memory. Tried to allocate 512.00 GiB (GPU 6; 10.76 GiB total capacity; 1.47 GiB already allocated; 8.11 GiB free; 1.94 GiB reserved in total by PyTorch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4096/4096 [00:10<00:00, 390.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 184/4096 [00:00<00:02, 1822.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed computing util_loss as batch. Trying sequential valuations computation. Decrease dimensions to fix. Error:\n",
      " CUDA out of memory. Tried to allocate 512.00 GiB (GPU 6; 10.76 GiB total capacity; 1.47 GiB already allocated; 8.11 GiB free; 1.94 GiB reserved in total by PyTorch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4096/4096 [00:10<00:00, 390.98it/s]\n",
      "  4%|▍         | 184/4096 [00:00<00:02, 1821.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed computing util_loss as batch. Trying sequential valuations computation. Decrease dimensions to fix. Error:\n",
      " CUDA out of memory. Tried to allocate 512.00 GiB (GPU 6; 10.76 GiB total capacity; 1.47 GiB already allocated; 8.11 GiB free; 1.94 GiB reserved in total by PyTorch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4096/4096 [00:10<00:00, 390.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 184/4096 [00:00<00:02, 1817.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed computing util_loss as batch. Trying sequential valuations computation. Decrease dimensions to fix. Error:\n",
      " CUDA out of memory. Tried to allocate 512.00 GiB (GPU 6; 10.76 GiB total capacity; 1.47 GiB already allocated; 8.11 GiB free; 1.94 GiB reserved in total by PyTorch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4096/4096 [00:10<00:00, 390.89it/s]\n",
      "  4%|▍         | 184/4096 [00:00<00:02, 1821.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed computing util_loss as batch. Trying sequential valuations computation. Decrease dimensions to fix. Error:\n",
      " CUDA out of memory. Tried to allocate 512.00 GiB (GPU 6; 10.76 GiB total capacity; 1.47 GiB already allocated; 8.11 GiB free; 1.94 GiB reserved in total by PyTorch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4096/4096 [00:10<00:00, 390.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 184/4096 [00:00<00:02, 1821.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed computing util_loss as batch. Trying sequential valuations computation. Decrease dimensions to fix. Error:\n",
      " CUDA out of memory. Tried to allocate 512.00 GiB (GPU 6; 10.76 GiB total capacity; 1.47 GiB already allocated; 8.11 GiB free; 1.94 GiB reserved in total by PyTorch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4096/4096 [00:10<00:00, 390.85it/s]\n",
      "  4%|▍         | 184/4096 [00:00<00:02, 1819.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed computing util_loss as batch. Trying sequential valuations computation. Decrease dimensions to fix. Error:\n",
      " CUDA out of memory. Tried to allocate 512.00 GiB (GPU 6; 10.76 GiB total capacity; 1.47 GiB already allocated; 8.11 GiB free; 1.94 GiB reserved in total by PyTorch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4096/4096 [00:10<00:00, 390.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 184/4096 [00:00<00:02, 1818.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed computing util_loss as batch. Trying sequential valuations computation. Decrease dimensions to fix. Error:\n",
      " CUDA out of memory. Tried to allocate 512.00 GiB (GPU 6; 10.76 GiB total capacity; 1.47 GiB already allocated; 8.11 GiB free; 1.94 GiB reserved in total by PyTorch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4096/4096 [00:10<00:00, 390.83it/s]\n",
      "  4%|▍         | 184/4096 [00:00<00:02, 1821.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed computing util_loss as batch. Trying sequential valuations computation. Decrease dimensions to fix. Error:\n",
      " CUDA out of memory. Tried to allocate 512.00 GiB (GPU 6; 10.76 GiB total capacity; 1.47 GiB already allocated; 8.11 GiB free; 1.94 GiB reserved in total by PyTorch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4096/4096 [00:10<00:00, 390.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 184/4096 [00:00<00:02, 1822.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed computing util_loss as batch. Trying sequential valuations computation. Decrease dimensions to fix. Error:\n",
      " CUDA out of memory. Tried to allocate 512.00 GiB (GPU 6; 10.76 GiB total capacity; 1.47 GiB already allocated; 8.11 GiB free; 1.94 GiB reserved in total by PyTorch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4096/4096 [00:10<00:00, 390.85it/s]\n",
      "  4%|▍         | 184/4096 [00:00<00:02, 1820.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed computing util_loss as batch. Trying sequential valuations computation. Decrease dimensions to fix. Error:\n",
      " CUDA out of memory. Tried to allocate 512.00 GiB (GPU 6; 10.76 GiB total capacity; 1.47 GiB already allocated; 8.11 GiB free; 1.94 GiB reserved in total by PyTorch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4096/4096 [00:10<00:00, 390.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 184/4096 [00:00<00:02, 1822.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed computing util_loss as batch. Trying sequential valuations computation. Decrease dimensions to fix. Error:\n",
      " CUDA out of memory. Tried to allocate 512.00 GiB (GPU 6; 10.76 GiB total capacity; 1.47 GiB already allocated; 8.11 GiB free; 1.94 GiB reserved in total by PyTorch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4096/4096 [00:10<00:00, 390.85it/s]\n",
      "  4%|▍         | 184/4096 [00:00<00:02, 1819.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed computing util_loss as batch. Trying sequential valuations computation. Decrease dimensions to fix. Error:\n",
      " CUDA out of memory. Tried to allocate 512.00 GiB (GPU 6; 10.76 GiB total capacity; 1.47 GiB already allocated; 8.11 GiB free; 1.94 GiB reserved in total by PyTorch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4096/4096 [00:10<00:00, 390.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 184/4096 [00:00<00:02, 1823.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed computing util_loss as batch. Trying sequential valuations computation. Decrease dimensions to fix. Error:\n",
      " CUDA out of memory. Tried to allocate 512.00 GiB (GPU 6; 10.76 GiB total capacity; 1.47 GiB already allocated; 8.11 GiB free; 1.94 GiB reserved in total by PyTorch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4096/4096 [00:10<00:00, 390.84it/s]\n",
      "  4%|▍         | 184/4096 [00:00<00:02, 1819.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed computing util_loss as batch. Trying sequential valuations computation. Decrease dimensions to fix. Error:\n",
      " CUDA out of memory. Tried to allocate 512.00 GiB (GPU 6; 10.76 GiB total capacity; 1.47 GiB already allocated; 8.11 GiB free; 1.94 GiB reserved in total by PyTorch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4096/4096 [00:10<00:00, 390.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 184/4096 [00:00<00:02, 1822.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed computing util_loss as batch. Trying sequential valuations computation. Decrease dimensions to fix. Error:\n",
      " CUDA out of memory. Tried to allocate 512.00 GiB (GPU 6; 10.76 GiB total capacity; 1.47 GiB already allocated; 8.11 GiB free; 1.94 GiB reserved in total by PyTorch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4096/4096 [00:10<00:00, 390.84it/s]\n",
      "  4%|▍         | 184/4096 [00:00<00:02, 1820.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed computing util_loss as batch. Trying sequential valuations computation. Decrease dimensions to fix. Error:\n",
      " CUDA out of memory. Tried to allocate 512.00 GiB (GPU 6; 10.76 GiB total capacity; 1.47 GiB already allocated; 8.11 GiB free; 1.94 GiB reserved in total by PyTorch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4096/4096 [00:10<00:00, 390.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 184/4096 [00:00<00:02, 1822.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed computing util_loss as batch. Trying sequential valuations computation. Decrease dimensions to fix. Error:\n",
      " CUDA out of memory. Tried to allocate 512.00 GiB (GPU 6; 10.76 GiB total capacity; 1.47 GiB already allocated; 8.11 GiB free; 1.94 GiB reserved in total by PyTorch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4096/4096 [00:10<00:00, 390.85it/s]\n",
      "  4%|▍         | 184/4096 [00:00<00:02, 1821.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed computing util_loss as batch. Trying sequential valuations computation. Decrease dimensions to fix. Error:\n",
      " CUDA out of memory. Tried to allocate 512.00 GiB (GPU 6; 10.76 GiB total capacity; 1.47 GiB already allocated; 8.11 GiB free; 1.94 GiB reserved in total by PyTorch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4096/4096 [00:10<00:00, 390.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 184/4096 [00:00<00:02, 1821.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed computing util_loss as batch. Trying sequential valuations computation. Decrease dimensions to fix. Error:\n",
      " CUDA out of memory. Tried to allocate 512.00 GiB (GPU 6; 10.76 GiB total capacity; 1.47 GiB already allocated; 8.11 GiB free; 1.94 GiB reserved in total by PyTorch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4096/4096 [00:10<00:00, 390.85it/s]\n",
      "  4%|▍         | 184/4096 [00:00<00:02, 1821.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed computing util_loss as batch. Trying sequential valuations computation. Decrease dimensions to fix. Error:\n",
      " CUDA out of memory. Tried to allocate 512.00 GiB (GPU 6; 10.76 GiB total capacity; 1.47 GiB already allocated; 8.11 GiB free; 1.94 GiB reserved in total by PyTorch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4096/4096 [00:10<00:00, 390.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 184/4096 [00:00<00:02, 1822.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed computing util_loss as batch. Trying sequential valuations computation. Decrease dimensions to fix. Error:\n",
      " CUDA out of memory. Tried to allocate 512.00 GiB (GPU 6; 10.76 GiB total capacity; 1.47 GiB already allocated; 8.11 GiB free; 1.94 GiB reserved in total by PyTorch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4096/4096 [00:10<00:00, 390.85it/s]\n",
      "  4%|▍         | 184/4096 [00:00<00:02, 1821.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed computing util_loss as batch. Trying sequential valuations computation. Decrease dimensions to fix. Error:\n",
      " CUDA out of memory. Tried to allocate 512.00 GiB (GPU 6; 10.76 GiB total capacity; 1.47 GiB already allocated; 8.11 GiB free; 1.94 GiB reserved in total by PyTorch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4096/4096 [00:10<00:00, 390.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 184/4096 [00:00<00:02, 1816.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed computing util_loss as batch. Trying sequential valuations computation. Decrease dimensions to fix. Error:\n",
      " CUDA out of memory. Tried to allocate 512.00 GiB (GPU 6; 10.76 GiB total capacity; 1.47 GiB already allocated; 8.11 GiB free; 1.94 GiB reserved in total by PyTorch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4096/4096 [00:10<00:00, 390.83it/s]\n",
      "  4%|▍         | 184/4096 [00:00<00:02, 1821.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed computing util_loss as batch. Trying sequential valuations computation. Decrease dimensions to fix. Error:\n",
      " CUDA out of memory. Tried to allocate 512.00 GiB (GPU 6; 10.76 GiB total capacity; 1.47 GiB already allocated; 8.11 GiB free; 1.94 GiB reserved in total by PyTorch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4096/4096 [00:10<00:00, 390.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 184/4096 [00:00<00:02, 1822.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed computing util_loss as batch. Trying sequential valuations computation. Decrease dimensions to fix. Error:\n",
      " CUDA out of memory. Tried to allocate 512.00 GiB (GPU 6; 10.76 GiB total capacity; 1.47 GiB already allocated; 8.11 GiB free; 1.94 GiB reserved in total by PyTorch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4096/4096 [00:10<00:00, 390.86it/s]\n",
      "  4%|▍         | 184/4096 [00:00<00:02, 1820.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed computing util_loss as batch. Trying sequential valuations computation. Decrease dimensions to fix. Error:\n",
      " CUDA out of memory. Tried to allocate 512.00 GiB (GPU 6; 10.76 GiB total capacity; 1.47 GiB already allocated; 8.11 GiB free; 1.94 GiB reserved in total by PyTorch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4096/4096 [00:10<00:00, 390.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 184/4096 [00:00<00:02, 1823.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed computing util_loss as batch. Trying sequential valuations computation. Decrease dimensions to fix. Error:\n",
      " CUDA out of memory. Tried to allocate 512.00 GiB (GPU 6; 10.76 GiB total capacity; 1.47 GiB already allocated; 8.11 GiB free; 1.94 GiB reserved in total by PyTorch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4096/4096 [00:10<00:00, 390.86it/s]\n",
      "  4%|▍         | 184/4096 [00:00<00:02, 1821.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed computing util_loss as batch. Trying sequential valuations computation. Decrease dimensions to fix. Error:\n",
      " CUDA out of memory. Tried to allocate 512.00 GiB (GPU 6; 10.76 GiB total capacity; 1.47 GiB already allocated; 8.11 GiB free; 1.94 GiB reserved in total by PyTorch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4096/4096 [00:10<00:00, 390.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weak\n",
      " \tExa mean 0.005219568498432636, std 0.0005537341348826885\n",
      " \tMexi mean 0.02697094716131687 std 0.006576715037226677\n",
      "Strong\n",
      " \tExa mean 0.013147570192813873, std 0.0018447418697178364\n",
      " \tMexi mean 0.05545806884765625 std 0.010918489657342434\n"
     ]
    }
   ],
   "source": [
    "exa_losses_weak = []\n",
    "mexi_losses_weak = []\n",
    "exa_losses_strong = []\n",
    "mexi_losses_strong = []\n",
    "for i in range(20):\n",
    "    print(i)\n",
    "    experiment.bne_env[0].prepare_iteration()\n",
    "    # weak\n",
    "    agent = experiment.bne_env[0].agents[0]\n",
    "    valuation = agent.valuations[:util_loss_batch_size, ...]\n",
    "    grid = agent.get_valuation_grid(util_loss_grid_size, True)\n",
    "    eq_bid_profile = torch.empty(util_loss_batch_size, experiment.n_players, agent.n_items)\n",
    "    for a in experiment.bne_env[0].agents:\n",
    "        eq_bid_profile[:, a.player_position, :] = a.get_action()[:util_loss_batch_size, ...]\n",
    "    ex_i_loss, _ = metrics.ex_interim_util_loss(\n",
    "        experiment.mechanism,eq_bid_profile, agent, valuation, grid)\n",
    "    exa_losses_weak.append(ex_i_loss.mean().item())\n",
    "    mexi_losses_weak.append(ex_i_loss.max().item())\n",
    "    # strong\n",
    "    agent = experiment.bne_env[0].agents[1]\n",
    "    valuation = agent.valuations[:util_loss_batch_size, ...]\n",
    "    grid = agent.get_valuation_grid(util_loss_grid_size, True)\n",
    "    eq_bid_profile = torch.empty(util_loss_batch_size, experiment.n_players, agent.n_items)\n",
    "    for a in experiment.bne_env[0].agents:\n",
    "        eq_bid_profile[:, a.player_position, :] = a.get_action()[:util_loss_batch_size, ...]\n",
    "    ex_i_loss, _ = metrics.ex_interim_util_loss(\n",
    "        experiment.mechanism,eq_bid_profile, agent, valuation, grid)\n",
    "    exa_losses_strong.append(ex_i_loss.mean().item())\n",
    "    mexi_losses_strong.append(ex_i_loss.max().item())\n",
    "uniform_asym_overlap_exa_weak = torch.tensor(exa_losses_weak)\n",
    "uniform_asym_overlap_mexi_weak = torch.tensor(mexi_losses_weak)\n",
    "uniform_asym_overlap_exa_strong = torch.tensor(exa_losses_strong)\n",
    "uniform_asym_overlap_mexi_strong = torch.tensor(mexi_losses_strong)\n",
    "print(f\"Weak\\n \\tExa mean {uniform_asym_overlap_exa_weak.mean().item()}, std {uniform_asym_overlap_exa_weak.std().item()}\\n \\tMexi mean { uniform_asym_overlap_mexi_weak.mean().item()} std {    uniform_asym_overlap_mexi_weak.std().item()}\")\n",
    "print(f\"Strong\\n \\tExa mean {    uniform_asym_overlap_exa_strong.mean().item()}, std {    uniform_asym_overlap_exa_strong.std().item()}\\n \\tMexi mean {    uniform_asym_overlap_mexi_strong.mean().item()} std {    uniform_asym_overlap_mexi_strong.std().item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0070, 0.0048, 0.0053, 0.0061, 0.0058, 0.0053, 0.0042, 0.0043, 0.0053,\n",
       "        0.0063, 0.0048, 0.0048, 0.0045, 0.0048, 0.0064, 0.0050, 0.0069, 0.0055,\n",
       "        0.0045, 0.0050])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniform_asym_overlap_exa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(0.0008),\n",
       " tensor(0.0006),\n",
       " tensor(0.0010),\n",
       " tensor(0.0008),\n",
       " tensor(0.0015),\n",
       " tensor(0.0007),\n",
       " tensor(0.0014),\n",
       " tensor(0.0014),\n",
       " tensor(0.0012),\n",
       " tensor(0.0005),\n",
       " tensor(0.0002),\n",
       " tensor(9.1984e-05),\n",
       " tensor(0.0002),\n",
       " tensor(0.0010),\n",
       " tensor(0.0009),\n",
       " tensor(0.0011),\n",
       " tensor(0.0011)]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[uniform_asym_overlap_exa_weak[i-3:i].max()  - uniform_asym_overlap_exa_weak[i-3:i].min() for i in range(3,20)]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(0.0046),\n",
       " tensor(0.0046),\n",
       " tensor(0.0008),\n",
       " tensor(0.0030),\n",
       " tensor(0.0036),\n",
       " tensor(0.0015),\n",
       " tensor(0.0041),\n",
       " tensor(0.0034),\n",
       " tensor(0.0041),\n",
       " tensor(0.0041),\n",
       " tensor(0.0050),\n",
       " tensor(0.0050),\n",
       " tensor(0.0029),\n",
       " tensor(0.0005),\n",
       " tensor(0.0031),\n",
       " tensor(0.0031),\n",
       " tensor(0.0035)]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[uniform_asym_overlap_exa_strong[i-3:i].max()  - uniform_asym_overlap_exa_strong[i-3:i].min() for i in range(3,20)]   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
